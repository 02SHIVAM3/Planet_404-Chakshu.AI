{"file_contents":{"app.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport joblib\nimport json\nimport os\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\ntry:\n    import shap\n    SHAP_AVAILABLE = True\nexcept ImportError:\n    SHAP_AVAILABLE = False\n\nfrom utils.data_preprocessing import ExoplanetPreprocessor\nfrom utils.model_training import ExoplanetClassifier\nfrom utils.shap_utils import SHAPExplainer\nfrom utils.hyperparameter_tuning import HyperparameterOptimizer\nfrom utils.ensemble_models import EnsembleClassifier\nfrom utils.calibration_utils import ModelCalibration\nfrom utils.feature_engineering import ExoplanetFeatureEngineer\n\n# Helper function to convert numpy types to Python native types for JSON serialization\ndef convert_to_json_serializable(obj):\n    \"\"\"Recursively convert numpy types to Python native types\"\"\"\n    if isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n        return int(obj)\n    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n        return float(obj)\n    elif isinstance(obj, dict):\n        return {key: convert_to_json_serializable(value) for key, value in obj.items()}\n    elif isinstance(obj, list):\n        return [convert_to_json_serializable(item) for item in obj]\n    elif isinstance(obj, tuple):\n        return tuple(convert_to_json_serializable(item) for item in obj)\n    return obj\n\n# Page configuration\nst.set_page_config(\n    page_title=\"ExoDetect: Exoplanet Classifier\",\n    page_icon=\"ü™ê\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Cache resources for performance\n@st.cache_resource\ndef load_model_artifacts():\n    \"\"\"Load trained model and preprocessing artifacts\"\"\"\n    artifacts = {}\n    model_dir = \"models\"\n    \n    if os.path.exists(f\"{model_dir}/model.joblib\"):\n        artifacts['model'] = joblib.load(f\"{model_dir}/model.joblib\")\n    if os.path.exists(f\"{model_dir}/preprocessor.joblib\"):\n        artifacts['preprocessor'] = joblib.load(f\"{model_dir}/preprocessor.joblib\")\n    if os.path.exists(f\"{model_dir}/feature_list.json\"):\n        with open(f\"{model_dir}/feature_list.json\", 'r') as f:\n            artifacts['features'] = json.load(f)\n    if os.path.exists(f\"{model_dir}/label_encoder.json\"):\n        with open(f\"{model_dir}/label_encoder.json\", 'r') as f:\n            artifacts['labels'] = json.load(f)\n    if os.path.exists(f\"{model_dir}/report.json\"):\n        with open(f\"{model_dir}/report.json\", 'r') as f:\n            artifacts['report'] = json.load(f)\n    \n    return artifacts\n\n@st.cache_resource\ndef load_shap_explainer(_model, X_sample):\n    \"\"\"Load SHAP explainer\"\"\"\n    return SHAPExplainer(_model, X_sample)\n\ndef main():\n    st.title(\"ü™ê CHAKSHU.AI - Hunting for Exoplanets with AI\")\n    st.markdown(\"### Classify astronomical objects as Confirmed planets, Candidates, or False Positives\")\n    \n    # Sidebar for navigation and model info\n    st.sidebar.title(\"Navigation\")\n    page = st.sidebar.selectbox(\"Choose a page\", \n                               [\"Train Model\", \"Make Predictions\", \"Model Performance\", \"Feature Analysis\"])\n    \n    # Model version selector\n    st.sidebar.divider()\n    st.sidebar.markdown(\"### üîÑ Model Management\")\n    \n    # Check for available model versions\n    version_history_file = \"models/version_history.json\"\n    if os.path.exists(version_history_file):\n        with open(version_history_file, 'r') as f:\n            version_history = json.load(f)\n        \n        if version_history:\n            # Create display options for each version\n            version_options = {}\n            for i, version in enumerate(reversed(version_history)):\n                timestamp = version.get('timestamp', f'Version {i+1}')\n                model_type = version.get('model_type', 'Unknown')\n                accuracy = version.get('accuracy', 0)\n                display_name = f\"{timestamp} - {model_type} ({accuracy:.1%})\"\n                version_options[display_name] = f\"v_{timestamp}\"\n            \n            # Add current model option\n            version_options = {\"Current (Latest)\" : \"current\", **version_options}\n            \n            selected_version_display = st.sidebar.selectbox(\n                \"Select Model Version\",\n                options=list(version_options.keys()),\n                help=\"Choose a model version to load\"\n            )\n            \n            selected_version = version_options[selected_version_display]\n            \n            # Load selected version if not current\n            if selected_version != \"current\":\n                if st.sidebar.button(\"Load Selected Version\", type=\"primary\"):\n                    version_dir = f\"models/versions/{selected_version}\"\n                    if os.path.exists(version_dir):\n                        try:\n                            # Copy selected version to active model directory\n                            import shutil\n                            shutil.copy(f\"{version_dir}/model.joblib\", \"models/model.joblib\")\n                            shutil.copy(f\"{version_dir}/preprocessor.joblib\", \"models/preprocessor.joblib\")\n                            shutil.copy(f\"{version_dir}/report.json\", \"models/report.json\")\n                            if os.path.exists(f\"{version_dir}/feature_list.json\"):\n                                shutil.copy(f\"{version_dir}/feature_list.json\", \"models/feature_list.json\")\n                            \n                            st.sidebar.success(\"‚úÖ Model version loaded!\")\n                            st.cache_resource.clear()\n                            st.rerun()\n                        except Exception as e:\n                            st.sidebar.error(f\"Error loading version: {str(e)}\")\n    \n    # Show current model info\n    st.sidebar.divider()\n    artifacts = load_model_artifacts()\n    if artifacts and 'report' in artifacts:\n        st.sidebar.markdown(\"### üìä Current Model Info\")\n        report = artifacts['report']\n        st.sidebar.metric(\"Overall Accuracy\", f\"{report['overall_accuracy']:.1%}\")\n        if 'training_info' in report:\n            st.sidebar.caption(f\"Model: {report['training_info'].get('model_type', 'N/A')}\")\n            st.sidebar.caption(f\"Features: {report['training_info'].get('n_features', 'N/A')}\")\n    else:\n        st.sidebar.info(\"No model trained yet\")\n    \n    if page == \"Train Model\":\n        train_model_page()\n    elif page == \"Make Predictions\":\n        prediction_page()\n    elif page == \"Model Performance\":\n        model_performance_page()\n    elif page == \"Feature Analysis\":\n        feature_analysis_page()\n\ndef train_model_page():\n    st.header(\"üîß Train Exoplanet Classifier\")\n    \n    # File upload\n    uploaded_file = st.file_uploader(\n        \"Upload NASA Exoplanet Dataset (CSV)\", \n        type=['csv'],\n        help=\"Upload the cumulative NASA exoplanet dataset\"\n    )\n    \n    if uploaded_file is None:\n        # Try to use the default file\n        default_file = \"attached_assets/cumulative_2025.10.03_23.58.46_1759634390786.csv\"\n        if os.path.exists(default_file):\n            st.info(f\"Using default dataset: {default_file}\")\n            df = pd.read_csv(default_file, comment='#', low_memory=False)\n        else:\n            st.warning(\"Please upload the NASA exoplanet dataset to proceed.\")\n            return\n    else:\n        df = pd.read_csv(uploaded_file, comment='#', low_memory=False)\n    \n    st.success(f\"Dataset loaded: {len(df)} rows, {len(df.columns)} columns\")\n    \n    # Show data preview\n    with st.expander(\"Data Preview\", expanded=False):\n        st.dataframe(df.head(10))\n        st.write(f\"**Columns:** {', '.join(df.columns.tolist())}\")\n    \n    # Training parameters\n    col1, col2, col3 = st.columns(3)\n    with col1:\n        model_type = st.selectbox(\"Model Type\", [\"XGBoost\", \"LightGBM\", \"Random Forest\", \"Ensemble (Stacking)\"])\n    with col2:\n        test_size = st.slider(\"Test Size\", 0.1, 0.4, 0.25)\n    with col3:\n        random_state = st.number_input(\"Random State\", value=42, min_value=1)\n    \n    # Advanced options\n    st.markdown(\"### ‚öôÔ∏è Advanced Options\")\n    \n    # Feature Engineering\n    use_feature_engineering = st.checkbox(\"Enable Feature Engineering\", \n                                          help=\"Create derived features (ratios, interactions) for improved performance\")\n    \n    if use_feature_engineering:\n        fe_col1, fe_col2 = st.columns(2)\n        with fe_col1:\n            include_ratios = st.checkbox(\"Ratio Features\", value=True, \n                                         help=\"Create ratio features (e.g., planet/star radius)\")\n            include_interactions = st.checkbox(\"Interaction Features\", value=True,\n                                              help=\"Create multiplicative interactions\")\n        with fe_col2:\n            include_differences = st.checkbox(\"Difference Features\", value=True,\n                                             help=\"Create difference features from error bounds\")\n            include_polynomial = st.checkbox(\"Polynomial Features\", value=False,\n                                            help=\"Create polynomial features (degree 2)\")\n    \n    # Hyperparameter optimization\n    use_hp_optimization = st.checkbox(\"Enable Hyperparameter Optimization\", \n                                      help=\"Use RandomizedSearchCV to find optimal hyperparameters (slower but better performance)\")\n    \n    if use_hp_optimization:\n        hp_col1, hp_col2 = st.columns(2)\n        with hp_col1:\n            n_iter = st.slider(\"Number of iterations\", 10, 50, 20, \n                             help=\"Number of parameter settings sampled\")\n        with hp_col2:\n            cv_folds = st.slider(\"CV folds\", 3, 10, 5,\n                               help=\"Number of cross-validation folds\")\n    \n    if st.button(\"Train Model\", type=\"primary\"):\n        with st.spinner(\"Training model... This may take a few minutes.\"):\n            try:\n                # Initialize preprocessor and classifier\n                preprocessor = ExoplanetPreprocessor()\n                classifier = ExoplanetClassifier(model_type=model_type.lower().replace(\" \", \"\"))\n                \n                # Preprocess data\n                st.info(\"Preprocessing data...\")\n                X, y, feature_names = preprocessor.preprocess_data(df)\n                \n                if X is None or y is None:\n                    st.error(\"Failed to preprocess data. Please check the dataset format.\")\n                    return\n                \n                st.info(f\"Features selected: {len(feature_names)}\")\n                st.info(f\"Class distribution: {dict(pd.Series(y).value_counts())}\")\n                \n                # Feature engineering if enabled\n                if use_feature_engineering:\n                    st.warning(\"‚ö†Ô∏è Feature engineering is currently disabled to prevent data leakage. This feature will be re-implemented in a future update.\")\n                    # TODO: Refactor feature engineering to apply only on training data after train/test split\n                    # to prevent data leakage\n                \n                # Encode labels consistently before any training\n                from sklearn.preprocessing import LabelEncoder\n                label_encoder = LabelEncoder()\n                y_encoded = label_encoder.fit_transform(y)\n                \n                # Check if ensemble model is selected\n                if model_type == \"Ensemble (Stacking)\":\n                    st.info(\"üéØ Training ensemble model with stacking...\")\n                    from sklearn.model_selection import train_test_split\n                    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n                    \n                    # Split data with encoded labels\n                    X_train, X_test, y_train, y_test = train_test_split(\n                        X, y_encoded, test_size=test_size, random_state=random_state, stratify=y_encoded\n                    )\n                    \n                    # Create and train ensemble\n                    ensemble = EnsembleClassifier(random_state=random_state)\n                    \n                    # Evaluate base models first\n                    st.info(\"Evaluating base models...\")\n                    base_results = ensemble.evaluate_base_models(X_train, y_train, cv=5)\n                    \n                    with st.expander(\"Base Model Performance\"):\n                        for name, result in base_results.items():\n                            st.write(f\"**{name}**: {result['mean_score']:.4f} (+/- {result['std_score']:.4f})\")\n                    \n                    # Train stacking ensemble\n                    model = ensemble.train(X_train, y_train, label_encoder)\n                    \n                    # Evaluate on test set\n                    y_pred = ensemble.predict(X_test)\n                    accuracy = accuracy_score(y_test, y_pred)\n                    \n                    target_names = list(label_encoder.classes_)\n                    class_report = classification_report(\n                        y_test, y_pred, \n                        target_names=target_names,\n                        output_dict=True,\n                        zero_division=0\n                    )\n                    conf_matrix = confusion_matrix(y_test, y_pred)\n                    \n                    feature_importance = ensemble.get_feature_importance()\n                    \n                    results = {\n                        'model': model,\n                        'label_encoder': label_encoder,\n                        'accuracy': accuracy,\n                        'classification_report': class_report,\n                        'confusion_matrix': conf_matrix,\n                        'feature_importance': feature_importance,\n                        'X_test': X_test,\n                        'y_test': y_test,\n                        'y_pred': y_pred,\n                        'hp_optimization': {'enabled': False},\n                        'ensemble_info': {\n                            'type': 'stacking',\n                            'base_models': base_results\n                        }\n                    }\n                # Hyperparameter optimization if enabled (not for ensemble)\n                elif use_hp_optimization:\n                    st.info(\"üîç Optimizing hyperparameters with cross-validation...\")\n                    from sklearn.model_selection import train_test_split\n                    \n                    # Split data for optimization (labels already encoded above)\n                    X_train, X_test, y_train, y_test = train_test_split(\n                        X, y_encoded, test_size=test_size, random_state=random_state, stratify=y_encoded\n                    )\n                    \n                    # Run hyperparameter optimization\n                    optimizer = HyperparameterOptimizer(\n                        model_type=model_type.lower().replace(\" \", \"\"),\n                        n_iter=n_iter,\n                        cv=cv_folds,\n                        random_state=random_state\n                    )\n                    \n                    hp_results = optimizer.optimize(X_train, y_train, scoring='f1_macro')\n                    \n                    # Show optimization results\n                    st.success(f\"‚úÖ Best CV Score: {hp_results['best_score']:.4f}\")\n                    with st.expander(\"Best Parameters\"):\n                        st.json(hp_results['best_params'])\n                    \n                    # Use optimized model\n                    classifier.model = hp_results['best_model']\n                    classifier.label_encoder = label_encoder\n                    \n                    # Evaluate on test set\n                    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n                    y_pred = classifier.model.predict(X_test)\n                    accuracy = accuracy_score(y_test, y_pred)\n                    \n                    target_names = list(label_encoder.classes_)\n                    class_report = classification_report(\n                        y_test, y_pred, \n                        target_names=target_names,\n                        output_dict=True,\n                        zero_division=0\n                    )\n                    conf_matrix = confusion_matrix(y_test, y_pred)\n                    \n                    feature_importance = None\n                    if hasattr(classifier.model, 'feature_importances_'):\n                        feature_importance = classifier.model.feature_importances_\n                    \n                    results = {\n                        'model': classifier.model,\n                        'label_encoder': label_encoder,\n                        'accuracy': accuracy,\n                        'classification_report': class_report,\n                        'confusion_matrix': conf_matrix,\n                        'feature_importance': feature_importance,\n                        'X_test': X_test,\n                        'y_test': y_test,\n                        'y_pred': y_pred,\n                        'hp_optimization': {\n                            'enabled': True,\n                            'best_params': hp_results['best_params'],\n                            'best_cv_score': hp_results['best_score']\n                        }\n                    }\n                else:\n                    # Train model normally with encoded labels\n                    st.info(\"Training classifier...\")\n                    from sklearn.model_selection import train_test_split\n                    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n                    \n                    # Split data\n                    X_train, X_test, y_train, y_test = train_test_split(\n                        X, y_encoded, test_size=test_size, random_state=random_state, stratify=y_encoded\n                    )\n                    \n                    # Train using the classifier's create_model and train logic\n                    classifier.label_encoder = label_encoder\n                    n_classes = len(label_encoder.classes_)\n                    class_weights_dict = classifier.calculate_class_weights(y_train)\n                    classifier.create_model(n_classes, class_weights_dict)\n                    \n                    # Train model with sample weights\n                    if classifier.model_type in ['xgboost']:\n                        sample_weights = classifier.calculate_sample_weights(y_train, class_weights_dict)\n                        classifier.model.fit(X_train, y_train, sample_weight=sample_weights)\n                    else:\n                        classifier.model.fit(X_train, y_train)\n                    \n                    # Make predictions\n                    y_pred = classifier.model.predict(X_test)\n                    \n                    # Calculate metrics\n                    accuracy = accuracy_score(y_test, y_pred)\n                    target_names = list(label_encoder.classes_)\n                    class_report = classification_report(\n                        y_test, y_pred, \n                        target_names=target_names,\n                        output_dict=True,\n                        zero_division=0\n                    )\n                    conf_matrix = confusion_matrix(y_test, y_pred)\n                    \n                    feature_importance = None\n                    if hasattr(classifier.model, 'feature_importances_'):\n                        feature_importance = classifier.model.feature_importances_\n                    \n                    results = {\n                        'model': classifier.model,\n                        'label_encoder': label_encoder,\n                        'accuracy': accuracy,\n                        'classification_report': class_report,\n                        'confusion_matrix': conf_matrix,\n                        'feature_importance': feature_importance,\n                        'X_test': X_test,\n                        'y_test': y_test,\n                        'y_pred': y_pred,\n                        'hp_optimization': {'enabled': False}\n                    }\n                \n                # Calibration analysis\n                st.info(\"üìä Performing calibration analysis...\")\n                try:\n                    calibration = ModelCalibration(\n                        results['model'], \n                        results['X_test'], \n                        results['y_test'],\n                        list(results['label_encoder'].classes_)\n                    )\n                    \n                    # Get threshold recommendations\n                    threshold_recs = calibration.get_threshold_recommendations()\n                    results['calibration_thresholds'] = threshold_recs\n                    \n                    st.success(\"‚úÖ Calibration analysis complete\")\n                except Exception as e:\n                    st.warning(f\"Calibration analysis skipped: {str(e)}\")\n                    results['calibration_thresholds'] = {}\n                \n                # Save artifacts with versioning\n                os.makedirs(\"models\", exist_ok=True)\n                os.makedirs(\"models/versions\", exist_ok=True)\n                \n                # Create version info\n                import datetime\n                version_timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n                version_info = {\n                    'timestamp': version_timestamp,\n                    'model_type': model_type,\n                    'accuracy': float(results['accuracy']),\n                    'n_features': len(feature_names),\n                    'feature_engineering': use_feature_engineering if 'use_feature_engineering' in locals() else False,\n                    'hyperparameter_optimization': use_hp_optimization if 'use_hp_optimization' in locals() else False\n                }\n                \n                # Save current version as active\n                joblib.dump(results['model'], \"models/model.joblib\")\n                joblib.dump(preprocessor, \"models/preprocessor.joblib\")\n                joblib.dump({'X_test': results['X_test'], 'y_test': results['y_test']}, \"models/test_data.joblib\")\n                \n                # Prepare report data before saving\n                report_data = {\n                    'overall_accuracy': float(results['accuracy']),\n                    'classification_report': convert_to_json_serializable(results['classification_report']),\n                    'confusion_matrix': results['confusion_matrix'].tolist(),\n                    'feature_importance': results['feature_importance'].tolist() if results['feature_importance'] is not None else None,\n                    'calibration_thresholds': convert_to_json_serializable(results.get('calibration_thresholds', {})),\n                    'training_info': {\n                        'model_type': model_type,\n                        'test_size': float(test_size),\n                        'random_state': int(random_state),\n                        'n_features': len(feature_names),\n                        'n_samples': len(X),\n                        'hyperparameter_optimization': convert_to_json_serializable(results.get('hp_optimization', {'enabled': False}))\n                    }\n                }\n                \n                # Save versioned copy with complete artifacts\n                version_dir = f\"models/versions/v_{version_timestamp}\"\n                os.makedirs(version_dir, exist_ok=True)\n                joblib.dump(results['model'], f\"{version_dir}/model.joblib\")\n                joblib.dump(preprocessor, f\"{version_dir}/preprocessor.joblib\")\n                \n                # Save version-specific report\n                with open(f\"{version_dir}/report.json\", 'w') as f:\n                    json.dump(report_data, f, indent=2)\n                \n                # Save feature list for this version\n                with open(f\"{version_dir}/feature_list.json\", 'w') as f:\n                    json.dump(feature_names, f)\n                \n                # Save version metadata\n                with open(f\"{version_dir}/version_info.json\", 'w') as f:\n                    json.dump(version_info, f, indent=2)\n                \n                # Update version history\n                history_file = \"models/version_history.json\"\n                if os.path.exists(history_file):\n                    with open(history_file, 'r') as f:\n                        history = json.load(f)\n                else:\n                    history = []\n                \n                history.append(version_info)\n                \n                with open(history_file, 'w') as f:\n                    json.dump(history, f, indent=2)\n                \n                # Save feature list and labels for active model\n                with open(\"models/feature_list.json\", 'w') as f:\n                    json.dump(feature_names, f)\n                \n                with open(\"models/label_encoder.json\", 'w') as f:\n                    json.dump(list(results['label_encoder'].classes_), f)\n                \n                # Save active model report (report_data already defined above for versioning)\n                with open(\"models/report.json\", 'w') as f:\n                    json.dump(report_data, f, indent=2)\n                \n                # Display results\n                st.success(\"Model training completed!\")\n                \n                # Prominently display overall accuracy\n                st.markdown(\"### üéØ Model Performance Summary\")\n                col1, col2, col3 = st.columns(3)\n                with col1:\n                    st.metric(\"**Overall Accuracy**\", f\"{results['accuracy']:.1%}\", help=\"Overall classification accuracy on test set\")\n                    \n                with col2:\n                    # Get per-class metrics from classification report\n                    class_report = results['classification_report']\n                    if 'Confirmed' in class_report:\n                        confirmed_f1 = class_report['Confirmed']['f1-score']\n                        st.metric(\"Confirmed F1-Score\", f\"{confirmed_f1:.3f}\")\n                \n                with col3:\n                    if 'macro avg' in class_report:\n                        macro_f1 = class_report['macro avg']['f1-score']\n                        st.metric(\"Macro F1-Score\", f\"{macro_f1:.3f}\")\n                \n                # Show detailed classification report\n                st.subheader(\"üìä Classification Report\")\n                report_df = pd.DataFrame(results['classification_report']).T\n                st.dataframe(report_df)\n                \n                # Show confusion matrix\n                st.subheader(\"üéØ Confusion Matrix\")\n                fig, ax = plt.subplots(figsize=(8, 6))\n                sns.heatmap(results['confusion_matrix'], \n                           annot=True, \n                           fmt='d', \n                           cmap='Blues',\n                           xticklabels=results['label_encoder'].classes_,\n                           yticklabels=results['label_encoder'].classes_,\n                           ax=ax)\n                ax.set_title('Confusion Matrix')\n                ax.set_ylabel('True Label')\n                ax.set_xlabel('Predicted Label')\n                st.pyplot(fig)\n                \n                # Show version history\n                if os.path.exists(\"models/version_history.json\"):\n                    with st.expander(\"üìú Model Version History\"):\n                        with open(\"models/version_history.json\", 'r') as f:\n                            history = json.load(f)\n                        \n                        if len(history) > 0:\n                            history_df = pd.DataFrame(history)\n                            history_df = history_df.sort_values('timestamp', ascending=False)\n                            st.dataframe(history_df)\n                            \n                            # Highlight best model\n                            best_idx = history_df['accuracy'].idxmax()\n                            best_model = history_df.loc[best_idx]\n                            st.success(f\"üèÜ Best model: {best_model['timestamp']} (Accuracy: {best_model['accuracy']:.3f})\")\n                \n            except Exception as e:\n                st.error(f\"Training failed: {str(e)}\")\n                st.exception(e)\n\ndef prediction_page():\n    st.header(\"üîÆ Make Predictions\")\n    \n    # Load model artifacts\n    artifacts = load_model_artifacts()\n    \n    if not artifacts:\n        st.error(\"No trained model found. Please train a model first.\")\n        return\n    \n    if not all(key in artifacts for key in ['model', 'preprocessor', 'features', 'labels']):\n        st.error(\"Incomplete model artifacts. Please retrain the model.\")\n        return\n    \n    st.success(\"Model loaded successfully!\")\n    \n    # Prediction mode selection\n    prediction_mode = st.radio(\n        \"Choose prediction mode:\",\n        [\"Upload CSV File\", \"Manual Feature Entry\"]\n    )\n    \n    if prediction_mode == \"Upload CSV File\":\n        batch_prediction_interface(artifacts)\n    else:\n        manual_prediction_interface(artifacts)\n\ndef batch_prediction_interface(artifacts):\n    st.subheader(\"üìÅ Batch Predictions from CSV\")\n    \n    uploaded_file = st.file_uploader(\n        \"Upload CSV file for prediction\", \n        type=['csv'],\n        help=\"Upload a CSV file with the same features as the training data\"\n    )\n    \n    if uploaded_file is not None:\n        try:\n            df = pd.read_csv(uploaded_file)\n            st.info(f\"File uploaded: {len(df)} rows, {len(df.columns)} columns\")\n            \n            with st.expander(\"Data Preview\", expanded=True):\n                st.dataframe(df.head())\n            \n            if st.button(\"Generate Predictions\", type=\"primary\"):\n                with st.spinner(\"Generating predictions...\"):\n                    # Preprocess the data\n                    preprocessor = artifacts['preprocessor']\n                    X_processed = preprocessor.transform_new_data(df, artifacts['features'])\n                    \n                    if X_processed is not None:\n                        # Make predictions\n                        model = artifacts['model']\n                        predictions = model.predict(X_processed)\n                        probabilities = model.predict_proba(X_processed)\n                        \n                        # Create results dataframe\n                        results_df = df.copy()\n                        results_df['Predicted_Class'] = predictions\n                        \n                        # Add probability columns\n                        for i, label in enumerate(artifacts['labels']):\n                            results_df[f'Probability_{label}'] = probabilities[:, i]\n                        \n                        st.success(f\"Predictions generated for {len(results_df)} rows!\")\n                        \n                        # Show results\n                        st.subheader(\"üìä Prediction Results\")\n                        st.dataframe(results_df)\n                        \n                        # Download button\n                        csv = results_df.to_csv(index=False)\n                        st.download_button(\n                            label=\"Download Predictions as CSV\",\n                            data=csv,\n                            file_name=\"exoplanet_predictions.csv\",\n                            mime=\"text/csv\"\n                        )\n                        \n                        # Show prediction distribution\n                        st.subheader(\"üìà Prediction Distribution\")\n                        pred_counts = pd.Series(predictions).value_counts()\n                        fig = px.bar(x=pred_counts.index, y=pred_counts.values, \n                                   title=\"Distribution of Predictions\")\n                        fig.update_xaxes(title=\"Predicted Class\")\n                        fig.update_yaxes(title=\"Count\")\n                        st.plotly_chart(fig)\n                        \n                    else:\n                        st.error(\"Failed to preprocess the uploaded data. Please check the format and features.\")\n        \n        except Exception as e:\n            st.error(f\"Error processing file: {str(e)}\")\n\ndef manual_prediction_interface(artifacts):\n    st.subheader(\"‚úèÔ∏è Manual Feature Entry\")\n    \n    features = artifacts['features']\n    \n    st.info(f\"Enter values for the following {len(features)} features:\")\n    \n    # Create input fields for each feature\n    feature_values = {}\n    \n    # Organize features in columns for better layout\n    n_cols = 3\n    cols = st.columns(n_cols)\n    \n    for i, feature in enumerate(features):\n        col_idx = i % n_cols\n        with cols[col_idx]:\n            # Provide helpful tooltips and reasonable defaults\n            if 'period' in feature.lower():\n                feature_values[feature] = st.number_input(\n                    f\"{feature} (days)\", \n                    value=10.0, \n                    help=\"Orbital period in days\"\n                )\n            elif 'radius' in feature.lower() or 'prad' in feature.lower():\n                feature_values[feature] = st.number_input(\n                    f\"{feature} (Earth radii)\", \n                    value=1.0, \n                    help=\"Planetary radius in Earth radii\"\n                )\n            elif 'depth' in feature.lower():\n                feature_values[feature] = st.number_input(\n                    f\"{feature} (ppm)\", \n                    value=1000.0, \n                    help=\"Transit depth in parts per million\"\n                )\n            elif 'temp' in feature.lower() or 'teff' in feature.lower():\n                feature_values[feature] = st.number_input(\n                    f\"{feature} (K)\", \n                    value=5000.0, \n                    help=\"Temperature in Kelvin\"\n                )\n            elif 'mag' in feature.lower():\n                feature_values[feature] = st.number_input(\n                    f\"{feature} (mag)\", \n                    value=15.0, \n                    help=\"Magnitude\"\n                )\n            else:\n                feature_values[feature] = st.number_input(\n                    feature, \n                    value=1.0\n                )\n    \n    if st.button(\"Predict\", type=\"primary\"):\n        try:\n            # Create DataFrame with the input values\n            input_df = pd.DataFrame([feature_values])\n            \n            # Preprocess\n            preprocessor = artifacts['preprocessor']\n            X_processed = preprocessor.transform_new_data(input_df, features)\n            \n            if X_processed is not None:\n                # Make prediction\n                model = artifacts['model']\n                prediction = model.predict(X_processed)[0]\n                probabilities = model.predict_proba(X_processed)[0]\n                \n                # Display results\n                st.success(\"Prediction completed!\")\n                \n                col1, col2 = st.columns(2)\n                \n                with col1:\n                    st.subheader(\"üéØ Predicted Class\")\n                    st.write(f\"**{prediction}**\")\n                    \n                    # Show probabilities\n                    st.subheader(\"üìä Class Probabilities\")\n                    for i, label in enumerate(artifacts['labels']):\n                        st.write(f\"**{label}**: {probabilities[i]:.3f}\")\n                \n                with col2:\n                    # Probability bar chart\n                    fig = px.bar(\n                        x=artifacts['labels'], \n                        y=probabilities,\n                        title=\"Prediction Probabilities\",\n                        color=probabilities,\n                        color_continuous_scale=\"viridis\"\n                    )\n                    fig.update_xaxes(title=\"Class\")\n                    fig.update_yaxes(title=\"Probability\")\n                    st.plotly_chart(fig)\n                \n                # SHAP explanation (if possible)\n                try:\n                    if hasattr(model, 'predict_proba') and len(X_processed) > 0:\n                        st.subheader(\"üîç Feature Importance (SHAP)\")\n                        \n                        # Create a small sample for SHAP background\n                        background_sample = X_processed[:1]  # Use the current prediction as background\n                        explainer = load_shap_explainer(model, background_sample)\n                        \n                        if explainer.explainer:\n                            shap_values = explainer.explain_prediction(X_processed)\n                            if shap_values is not None:\n                                # Create SHAP waterfall plot\n                                fig = explainer.create_waterfall_plot(shap_values[0], features, prediction)\n                                if fig:\n                                    st.pyplot(fig)\n                except Exception as e:\n                    st.warning(f\"Could not generate SHAP explanation: {str(e)}\")\n            \n            else:\n                st.error(\"Failed to preprocess the input data.\")\n                \n        except Exception as e:\n            st.error(f\"Prediction failed: {str(e)}\")\n            st.exception(e)\n\ndef model_performance_page():\n    st.header(\"üìà Model Performance Analysis\")\n    \n    # Load model artifacts\n    artifacts = load_model_artifacts()\n    \n    if not artifacts or 'report' not in artifacts:\n        st.error(\"No model performance data found. Please train a model first.\")\n        return\n    \n    report = artifacts['report']\n    \n    # Display overall accuracy prominently at the top\n    st.markdown(\"## üéØ Overall Model Accuracy\")\n    accuracy_col1, accuracy_col2, accuracy_col3 = st.columns([2, 1, 1])\n    with accuracy_col1:\n        st.markdown(f\"<h1 style='text-align: center; color: #1f77b4;'>{report['overall_accuracy']:.1%}</h1>\", unsafe_allow_html=True)\n        st.markdown(\"<p style='text-align: center;'>Classification Accuracy on Test Set</p>\", unsafe_allow_html=True)\n    \n    st.divider()\n    \n    # Overall metrics\n    st.subheader(\"üìä Detailed Performance Metrics\")\n    \n    col1, col2, col3, col4 = st.columns(4)\n    \n    with col1:\n        st.metric(\"Overall Accuracy\", f\"{report['overall_accuracy']:.3f}\")\n    \n    # Extract macro and weighted averages from classification report\n    class_report = report['classification_report']\n    \n    with col2:\n        if 'macro avg' in class_report:\n            macro_f1 = class_report['macro avg']['f1-score']\n            st.metric(\"Macro F1-Score\", f\"{macro_f1:.3f}\")\n    \n    with col3:\n        if 'weighted avg' in class_report:\n            weighted_f1 = class_report['weighted avg']['f1-score']\n            st.metric(\"Weighted F1-Score\", f\"{weighted_f1:.3f}\")\n    \n    with col4:\n        if 'Confirmed' in class_report:\n            confirmed_recall = class_report['Confirmed']['recall']\n            st.metric(\"Confirmed Recall\", f\"{confirmed_recall:.3f}\")\n    \n    # Per-class performance\n    st.subheader(\"üìä Per-Class Performance\")\n    \n    # Convert classification report to DataFrame for better display\n    class_df = pd.DataFrame(class_report).T\n    \n    # Filter out the summary rows for the main display\n    main_classes = [col for col in class_df.index if col not in ['accuracy', 'macro avg', 'weighted avg']]\n    class_metrics_df = class_df.loc[main_classes, ['precision', 'recall', 'f1-score', 'support']]\n    \n    st.dataframe(class_metrics_df)\n    \n    # Visualize per-class metrics\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        # Precision, Recall, F1 comparison\n        metrics_data = []\n        for class_name in main_classes:\n            if class_name in class_report:\n                metrics_data.append({\n                    'Class': class_name,\n                    'Precision': class_report[class_name]['precision'],\n                    'Recall': class_report[class_name]['recall'],\n                    'F1-Score': class_report[class_name]['f1-score']\n                })\n        \n        if metrics_data:\n            metrics_df = pd.DataFrame(metrics_data)\n            fig = px.bar(\n                metrics_df.melt(id_vars=['Class'], \n                               value_vars=['Precision', 'Recall', 'F1-Score']),\n                x='Class', y='value', color='variable',\n                title=\"Per-Class Performance Metrics\",\n                barmode='group'\n            )\n            fig.update_yaxes(title=\"Score\")\n            st.plotly_chart(fig)\n    \n    with col2:\n        # Support (number of samples) per class\n        support_data = []\n        for class_name in main_classes:\n            if class_name in class_report:\n                support_data.append({\n                    'Class': class_name,\n                    'Support': class_report[class_name]['support']\n                })\n        \n        if support_data:\n            support_df = pd.DataFrame(support_data)\n            fig = px.pie(\n                support_df, \n                values='Support', \n                names='Class',\n                title=\"Class Distribution (Support)\"\n            )\n            st.plotly_chart(fig)\n    \n    # Confusion Matrix\n    st.subheader(\"üéØ Confusion Matrix\")\n    \n    if 'confusion_matrix' in report and artifacts.get('labels'):\n        conf_matrix = np.array(report['confusion_matrix'])\n        labels = artifacts['labels']\n        \n        fig, ax = plt.subplots(figsize=(10, 8))\n        sns.heatmap(\n            conf_matrix, \n            annot=True, \n            fmt='d', \n            cmap='Blues',\n            xticklabels=labels,\n            yticklabels=labels,\n            ax=ax\n        )\n        ax.set_title('Confusion Matrix', fontsize=16)\n        ax.set_ylabel('True Label', fontsize=12)\n        ax.set_xlabel('Predicted Label', fontsize=12)\n        st.pyplot(fig)\n        \n        # Confusion matrix as heatmap with Plotly for interactivity\n        fig = px.imshow(\n            conf_matrix,\n            labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"),\n            x=labels,\n            y=labels,\n            color_continuous_scale=\"Blues\",\n            title=\"Interactive Confusion Matrix\"\n        )\n        fig.update_traces(text=conf_matrix, texttemplate=\"%{text}\")\n        fig.update_xaxes(side=\"bottom\")\n        st.plotly_chart(fig)\n    \n    # Calibration and Threshold Analysis\n    st.subheader(\"üìê Model Calibration & Threshold Tuning\")\n    \n    # Load test data and model if available\n    if os.path.exists(\"models/test_data.joblib\") and os.path.exists(\"models/model.joblib\"):\n        try:\n            test_data = joblib.load(\"models/test_data.joblib\")\n            model = artifacts['model']\n            \n            calibration = ModelCalibration(\n                model,\n                test_data['X_test'],\n                test_data['y_test'],\n                artifacts['labels']\n            )\n            \n            # Show saved threshold recommendations\n            if 'calibration_thresholds' in report and report['calibration_thresholds']:\n                st.markdown(\"#### üéØ Recommended Probability Thresholds\")\n                thresh_df = pd.DataFrame(report['calibration_thresholds']).T\n                st.dataframe(thresh_df)\n            \n            # Interactive calibration analysis\n            with st.expander(\"üìä View Calibration Curves\", expanded=False):\n                # Select class for detailed analysis\n                class_idx = st.selectbox(\n                    \"Select class for detailed calibration analysis:\",\n                    range(len(artifacts['labels'])),\n                    format_func=lambda x: artifacts['labels'][x]\n                )\n                \n                cal_col1, cal_col2 = st.columns(2)\n                \n                with cal_col1:\n                    # Calibration curve\n                    fig_cal, brier = calibration.plot_calibration_curve(class_idx)\n                    st.pyplot(fig_cal)\n                    st.caption(f\"Brier Score: {brier:.4f} (lower is better)\")\n                \n                with cal_col2:\n                    # Threshold analysis\n                    fig_thresh, opt_thresh = calibration.plot_threshold_analysis(class_idx)\n                    st.pyplot(fig_thresh)\n                    st.caption(f\"Optimal F1 threshold: {opt_thresh:.3f}\")\n        \n        except Exception as e:\n            st.warning(f\"Could not load calibration data: {str(e)}\")\n    else:\n        st.info(\"Calibration analysis will be available after training a model.\")\n    \n    # Training information\n    st.subheader(\"‚ÑπÔ∏è Training Information\")\n    \n    if 'training_info' in report:\n        training_info = report['training_info']\n        \n        info_col1, info_col2 = st.columns(2)\n        \n        with info_col1:\n            st.write(f\"**Model Type:** {training_info.get('model_type', 'N/A')}\")\n            st.write(f\"**Number of Features:** {training_info.get('n_features', 'N/A')}\")\n            st.write(f\"**Number of Samples:** {training_info.get('n_samples', 'N/A')}\")\n        \n        with info_col2:\n            st.write(f\"**Test Size:** {training_info.get('test_size', 'N/A')}\")\n            st.write(f\"**Random State:** {training_info.get('random_state', 'N/A')}\")\n\ndef feature_analysis_page():\n    st.header(\"üîç Feature Analysis\")\n    \n    # Load model artifacts\n    artifacts = load_model_artifacts()\n    \n    if not artifacts:\n        st.error(\"No trained model found. Please train a model first.\")\n        return\n    \n    if 'report' in artifacts and 'feature_importance' in artifacts['report']:\n        feature_importance = artifacts['report']['feature_importance']\n        features = artifacts['features']\n        \n        if feature_importance and len(feature_importance) == len(features):\n            st.subheader(\"üìä Feature Importance\")\n            \n            # Create feature importance DataFrame\n            importance_df = pd.DataFrame({\n                'Feature': features,\n                'Importance': feature_importance\n            }).sort_values('Importance', ascending=False)\n            \n            # Display top features\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                st.write(\"**Top 10 Most Important Features:**\")\n                st.dataframe(importance_df.head(10))\n            \n            with col2:\n                # Feature importance plot\n                fig = px.bar(\n                    importance_df.head(15), \n                    x='Importance', \n                    y='Feature',\n                    orientation='h',\n                    title=\"Top 15 Feature Importance\"\n                )\n                fig.update_yaxes(categoryorder=\"total ascending\")\n                st.plotly_chart(fig)\n            \n            # Full feature importance (expandable)\n            with st.expander(\"All Features Importance\", expanded=False):\n                st.dataframe(importance_df)\n        \n        else:\n            st.warning(\"Feature importance data is not available or inconsistent.\")\n    \n    else:\n        st.warning(\"Feature importance data is not available. This might be because the model doesn't support feature importance or it wasn't saved during training.\")\n    \n    # Feature descriptions and statistics\n    st.subheader(\"üìã Feature Descriptions\")\n    \n    if 'features' in artifacts:\n        features = artifacts['features']\n        \n        feature_descriptions = {\n            'koi_period': 'Orbital Period (days) - Time for one complete orbit',\n            'koi_period_err1': 'Orbital Period Upper Unc.',\n            'koi_period_err2': 'Orbital Period Lower Unc.',\n            'koi_duration': 'Transit Duration (hours) - How long the planet blocks the star',\n            'koi_duration_err1': 'Transit Duration Upper Unc.',\n            'koi_duration_err2': 'Transit Duration Lower Unc.',\n            'koi_depth': 'Transit Depth (ppm) - Amount of starlight blocked during transit',\n            \n            'koi_prad': 'Planetary Radius (Earth radii) - Size of the planet',\n            'koi_teq': 'Equilibrium Temperature (K) - Expected planet temperature',\n            'koi_insol': 'Insolation Flux (Earth flux) - Amount of stellar radiation received',\n            'koi_model_snr': 'Transit Signal-to-Noise Ratio - Quality of the detection',\n            'koi_steff': 'Stellar Effective Temperature (K) - Temperature of the host star',\n            'koi_slogg': 'Stellar Surface Gravity - Density indicator of the host star',\n            'koi_srad': 'Stellar Radius (Solar radii) - Size of the host star',\n            'koi_kepmag': 'Kepler Magnitude - Brightness of the star',\n            'koi_impact': 'Impact Parameter - How centrally the planet transits',\n        }\n        \n        st.write(\"**Feature Descriptions:**\")\n        for feature in features:\n            description = feature_descriptions.get(feature, \"No description available\")\n            st.write(f\"‚Ä¢ **{feature}**: {description}\")\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":49552},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"streamlit>=1.50.0\",\n    \"plotly>=5.18.0\",\n    \"seaborn>=0.13.0\",\n    \"scikit-learn>=1.3.0\",\n    \"xgboost>=2.0.0\",\n    \"lightgbm>=4.0.0\",\n    \"matplotlib>=3.8.0\",\n    \"pandas>=2.1.0\",\n    \"numpy>=1.24.0\",\n    \"joblib>=1.3.0\",\n]\n\n[[tool.uv.index]]\nexplicit = true\nname = \"pytorch-cpu\"\nurl = \"https://download.pytorch.org/whl/cpu\"\n\n[tool.uv.sources]\nAA-module = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nABlooper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nAnalysisG = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nAutoRAG = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nBERTeam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nBxTorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nByaldi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCALM-Pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCOPEX-high-rate-compression-quality-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCityLearn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCoCa-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCoLT5-attention = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nComfyUI-EasyNodes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCrawl4AI = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDALL-E = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDI-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDatasetRising = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDeepCache = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDeepMatter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDraugr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nESRNN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nEn-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nExpoSeq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nFLAML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nFSRS-Optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGANDLF = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGQLAlchemy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGhostScan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGraKeL = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nHEBO = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nIOPaint = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nISLP = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nInvokeAI = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nJAEN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nKapoorLabs-Lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nLightAutoML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nLingerGRN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nMMEdu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nMRzeroCore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nModeva = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNeuralFoil = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNiMARE = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNinjaTools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nOpenHosta = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nOpenNMT-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPOT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPVNet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPaLM-rlhf-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPepperPepper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPiML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPoutyne = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nQNCP = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRAGatouille = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRareGO = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRealtimeSTT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRelevanceAI-Workflows-Core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nResemblyzer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nScandEval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nSimba-UW-tf-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nSwissArmyTransformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTPOT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTTS = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTorchCRF = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTotalSegmentator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nUtilsRL = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nWhisperSpeech = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nXAISuite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\na-unet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\na5dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccelerate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccelerated-scan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccern-xyme = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nachatbot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nacids-rave = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nactorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nacvl-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadabelief-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadam-atan2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadan-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadapters = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadmin-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadtoolbox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadversarial-robustness-toolbox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naeiou = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naeon = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nafricanwhisper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nag-llama-api = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nagentdojo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nagilerl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-edge-torch-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-parrot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-transform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-olmo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-olmo-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-tango = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naicmder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naider-chat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naider-chat-x = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naif360 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naihwkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naimodelshare = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairtestProject = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairunner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naisak = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naislib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naisquared = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naistore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naithree = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nakasha-terminal = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalibi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalibi-detect = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalignn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nall-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp-pvt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallophant = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallosaurus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naloy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalpaca-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphafold2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphafold3-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphamed-federated = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphawave = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\namazon-braket-pennylane-plugin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\namazon-photos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanemoi-graphs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanemoi-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanomalib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\napache-beam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\napache-tvm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naperturedb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naphrodite-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naqlm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narcAGI2024 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narchisound = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nargbind = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narize = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narm-pytorch-utilities = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narray-api-compat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nassert-llm-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nasteroid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nasteroid-filterbanks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nastra-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nastrovision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\natomate2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nattacut = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-encoders-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-separator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudiocraft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudiolm-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauralis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauraloss = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauto-gptq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautoawq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautoawq-kernels = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.multimodal\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.tabular\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.timeseries\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautotrain-advanced = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\navdeepfake1m = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naws-fortuna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nax-platform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-automl-dnn-vision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-contrib-automl-dnn-forecasting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-evaluate-mlflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-train-automl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nb2bTools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbackpack-for-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbalrog-nle = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatch-face = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchalign = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchgeneratorsv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchtensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbbrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbenchpots = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbent = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbert-score = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbertopic = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbertviz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbestOf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbetty-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbig-sleep = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-core-cpp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-core-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-nano = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"bioimageio.core\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbitfount = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbitsandbytes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbittensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbittensor-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblackboxopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblanc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblindai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbm25-pt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nboltz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbotorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nboxmot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrainchain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbraindecode = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrevitas = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbriton = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrowsergym-visualwebarena = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbuzz-captions = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbyotrack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbyzerllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nc4v-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncalflops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncame-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncamel-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncamel-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncannai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncaptum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncarte-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncarvekit-colab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncatalyst = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausalml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausalnex = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncbrkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncca-zoo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncdp-backend = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellacdc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellfinder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellpose = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellxgene-census = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchattts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchemprop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchgnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchitra = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncircuitsvis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncjm-yolox-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclarinpl-embeddings = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclass-resolver = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassifier-free-guidance-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassiq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassy-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclean-fid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncleanvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-anytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-benchmark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-by-openai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-interrogator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-retrieval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncltk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclusterops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncnocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncnstd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoba = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncofi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncolbert-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncolpali-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-ray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-ray-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-train = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-train-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressed-tensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressed-tensors-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconcrete-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconfit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontextualSpellCheck = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontinual-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontrolnet-aux = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconvokit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoola = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoqui-tts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoqui-tts-trainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncraft-text-detector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncreme = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncrocodile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncrowd-kit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncryoSPHERE = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncsle-common = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncsle-system-identification = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nctgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncurated-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncut-cross-entropy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncvat-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncybertask = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nd3rlpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndalle-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndalle2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndanila-lib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndanling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndarts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndarwin-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndata-gradients = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatachain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndataclass-array = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndataeval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatarobot-drum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatarobotx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatumaro = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndctorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeep-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepchecks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepchem = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepctr-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepecho = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepepochs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepforest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeeplabcut = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepmd-kit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepmultilingualpunctuation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeeprobust = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepsparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepsparse-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepspeed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndenoising-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndescript-audio-codec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndescript-audiotools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndetecto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndetoxify = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndgenerate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndghs-imgutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndgl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndialogy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndice-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffgram = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffusers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndistilabel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndistrifuser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndnikit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocarray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndoclayout-yolo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocling-ibm-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocquery = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndomino-code-assist = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndreamsim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndropblock = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndruida = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndvclive = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne2-tts-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne2cnn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne3nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neasyocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nebtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\necallisto-ng = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nedsnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neffdet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neinx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neir-dl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neis1600 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neland = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nema-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nembedchain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nenformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nentmax = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nesm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nespaloma-charge = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nespnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\netils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\netna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevadb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevalscope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevaluate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nexllamav2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nextractable = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nface-alignment = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfacenet-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfacexlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfair-esm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq2n = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfaker-file = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfarm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfast-bert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfast-pytorch-kmeans = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastcore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastestimator-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfasttreeshap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfedml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfelupe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfemr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfft-conv-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfickling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfireworks-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflair = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflashrag-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflax = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflexgen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflgo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflopth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflowcept = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflytekitplugins-kfpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflytekitplugins-onnxpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfmbench = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfocal-frequency-loss = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfoldedtensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfractal-tasks-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfreegenius = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfreqtrade = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfschat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunasr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunctorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunlbm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunsor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngalore-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngarak = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngarf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngateloop-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngeffnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngenutility = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngfpgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngigagan-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngin-config = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nglasflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngliner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngluonts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngmft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngoogle-cloud-aiplatform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpforecaster = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpt3discord = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngrad-cam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngraph-weather = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngraphistry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngravitorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngretel-synthetics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngsplat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nguardrails-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nguidance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngymnasium = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhanlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhappytransformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhbutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nheavyball = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhezar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhf-deepali = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhf-doc-builder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhigher = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhjxdl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhkkang-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhordelib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhpsv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhuggingface-hub = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhummingbird-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhvae-backbone = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhya = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhypothesis-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-metrics-plugin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-watson-machine-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-watsonx-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nicetk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nicevision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niden = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nidvpackage = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niglovikov-helper-functions = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimagededup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimagen-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimaginAIry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimg2vec-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nincendio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninference-gpu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfinity-emb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfo-nce-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfoapps-mlops-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-dolomite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-sdg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-training = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninvisible-watermark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niobm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nipex-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niree-turbine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-azure-openai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-torchvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-training = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nitem-matching = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nivadomed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njaqpotpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njina = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njudo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njunky = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk-diffusion = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk1lib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkappadata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkappamodules = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkarbonn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkats = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkbnf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkedro-datasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkeybert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkeytotext = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkhoj = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkiui = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkonfuzio-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkornia = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkornia-moons = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkraken = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkwarray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkwimage = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlabml-nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlagent = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlaion-clap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlama-cleaner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlancedb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangcheck = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangroid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangtest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlayoutparser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nldp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleafmap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleap-ie = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleibniz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleptonai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nletmedoit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlhotse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlib310 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibpecos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibrec-auto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibretranslate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliger-kernel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliger-kernel-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-bolts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-fabric = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-habana = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-lite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightrag = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightweight-gan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightwood = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinear-attention-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinear-operator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliom-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlit-nlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitelama = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitgpt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-adapter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-instructor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-llms-huggingface = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-postprocessor-colbert-rerank = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-blender = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-foundry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-guard = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-rs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmcompressor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmlingua = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmvm-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlm-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlmdeploy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlmms-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlocal-attention = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlovely-tensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlpips = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlycoris-lora = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmace-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagic-pdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagicsoup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagvit2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmaite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanga-ocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanifest-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanipulation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmarker-pdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmatgl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmed-imagetools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedaka = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedcat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedmnist = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmegablocks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmegatron-energon = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmemos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmeshgpt-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmetatensor-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmflux = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmia-vgg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmiditok = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nminari = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nminicons = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nml2rt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlagents = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlbench-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlcroissant = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlpfile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlx-whisper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmaction2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmengine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmengine-lite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmpose = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmsegmentation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodeci-mdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodel2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodelscope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodelspec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonai-weekly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonotonic-alignment-search = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonty = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmosaicml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmosaicml-streaming = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmoshi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmteb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmtmtrain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmulti-quantization = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmyhand = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnGPT-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnaeural-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnapari = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnapatrackmater = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnara-wpe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnatten = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnbeats-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnebulae = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnemo-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneptune = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneptune-client = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnerfacc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnerfstudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnessai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnetcal = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneural-rag = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralforecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralnets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralprophet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuspell = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnevergrad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnexfort = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnimblephysics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnirtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnkululeko = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnlptooltest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnAudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnodely = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnsight = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnunetv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnoisereduce = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnonebot-plugin-nailongremove = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnowcasting-dataloader = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnowcasting-forecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnshtrainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnuwa-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnvflare = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnvidia-modelopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nocf-datapipes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nocnn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nogb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nohmeow-blurr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nolive-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nomlt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nommlx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonediff = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonediffx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonnx2pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonnx2torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopacus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-clip-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-flamingo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-interpreter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenbb-terminal-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenmim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenunmix = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-tokenizers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-xai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenwakeword = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopt-einsum-fx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-habana = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-intel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-neuron = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-quanto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptree = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna-dashboard = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna-integration = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noracle-ads = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\norbit-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\notx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutetts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutlines = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutlines-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npaddlenlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npai-easycv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npandasai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npanns-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npatchwork-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npeft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npegasuspy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npelutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npenn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nperforatedai-freemium = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nperformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npetastorm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npfio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npgmpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nphenolrs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nphobos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npi-zero-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npinecone-text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npiq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npix2tex = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npix2text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npnnx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npolicyengine-us-data = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npolyfuzz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npomegranate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npositional-encodings = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nprefigure = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nproduct-key-memory = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nptflops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nptwt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npulser-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npunctuators = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npy2ls = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyabsa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"pyannote.audio\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyawd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyclarity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npycox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyfemtet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyg-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npygrinder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyhealth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyhf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyiqa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npykeen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npykeops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npylance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npylineaGT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npymanopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npymde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npypots = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyqlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyqtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyro-ppl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npysentimiento = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyserini = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npysr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npythainlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npython-doctr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-fid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-forecasting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-ignite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-kinematics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-lightning-bolts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-metric-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-model-summary = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-msssim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-pfn-extras = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-pretrained-bert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-ranger = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-seed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-tabnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-tabular = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-toolbelt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-transformers-pvt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-triton-rocm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-warmup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-wavelets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch_optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch_revgrad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorchcv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorchltr2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyvene = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyvespa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqianfan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqibo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqiskit-machine-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nquanto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nquick-anomaly-detector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision-pytorch-backend = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision-pytorch-learner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nray-lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrclip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrealesrgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrecbole = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrecommenders = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nredcat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nreformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nregex-sampler = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nreplay-rec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrerankers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresearch-framework = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresemble-enhance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresnest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrf-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrf-groundingdino = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrfconv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrich-logger = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nring-attention-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrltrade-test = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrotary-embedding-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrsp-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrust-circuit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns2fft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns3prl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns3torchconnector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsaferx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsafetensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsagemaker-huggingface-inference-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsagemaker-ssh-helper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsalesforce-lavis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsalesforce-merlion = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsamv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscib-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscvi-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsdmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsecretflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegment-anything-hq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegment-anything-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegmentation-models-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nself-rewarding-lm-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsemantic-kernel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsemantic-router = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsenselab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsent2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsentence-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsequence-model-train = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nserotiny = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsevenn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsglang = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nshap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilero-api-server = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilero-vad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilicondiff-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsimclr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsimple-lama-inpainting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsinabs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsixdrepnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskforecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsktime = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsktmls = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nslangtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmartnoise-synth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmashed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmplx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmqtk-descriptors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmqtk-detection = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnntorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnorkel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnowflake-ml-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nso-vits-svc-fork = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsonusai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsony-custom-layers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsotopia = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-curated-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-experimental = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-huggingface-pipelines = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspan-marker = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspandrel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspandrel-extra-arches = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsparrow-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspatialdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspeechbrain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspeechtokenizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspikeinterface = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspikingjelly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotiflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotpython = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotriver = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsquirrel-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-baselines3 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-diffusion-sdkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-ts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanford-stk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanfordnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanza = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstartorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstreamtasks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstruct-eqtable = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstylegan2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsupar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuper-gradients = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuper-image = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuperlinked = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsupervisely = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsurya-ocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsvdiff-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarm-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarmauri = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarms-memory = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswebench = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsyft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsympytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsyne-tune = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsynthcity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nt5 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntab-transformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntabpfn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaming-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaming-transformers-rom1504 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaskwiz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntbparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntecton = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensor-parallel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorcircuit-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensordict = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensordict-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorrt-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntexify = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntext2text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntextattack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntfkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthepipe-api = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthinc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthingsvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthirdai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntianshou = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntidy3d = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntimesfm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntimm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntipo-kgen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntmnt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntoad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntomesd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntop2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-audiomentations = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-dct = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-delaunay = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-directml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ema = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-encoding = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-fidelity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-geometric = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-geopooling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-harmonics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-kmeans = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-lr-finder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-max-mem = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-optimi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ort = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-pitch-shift = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ppr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-pruning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-snippets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-stoi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-struct = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-tensorrt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchani = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchattacks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchaudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchbiggraph = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcfm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcrepe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdatasets-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdiffeq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdyn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchestra = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorcheval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorcheval-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchextractor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfcpe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfun = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfunc-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchgeo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchgeometry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchjpeg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchlayers-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmeta = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmocks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpippy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchprofile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchquantlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec-nightly-cpu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrl-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchscale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchserve = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchserve-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsnapshot-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchstain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsummaryX = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtext = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtnt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtnt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtyping = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchutil = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchvinecopulib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchviz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchx-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchxrayvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntotalspineseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntracebloc-package-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntrainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-lens = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-smaller-training-vocab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformers-domain-adaptation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransfusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransparent-background = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntreescope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntrolo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntsai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntslearn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nttspod = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntxtai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntyro = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nu8darts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nuhg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nuitestrunner-syberos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultimate-rvc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultralytics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultralytics-thop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunav = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunbabel-comet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunderthesea = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunfoldNd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunimernet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunitorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunitxt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunsloth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunsloth-zoo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunstructured = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunstructured-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nutilsd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nv-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvIQA = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvectice = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvector-quantize-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvectorhub-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nversatile-audio-upscaler = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvertexai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvesin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvgg-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvideo-representations-extractor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nviser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvision-datasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvisionmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvisu3d = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvit-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nviturka-nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvllm-flash-attn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvocos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvollseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwavmark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwdoc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisper-live = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisper-timestamped = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisperx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwilds = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwordllama = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nworker-automate-hub = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwxbtool = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nx-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nx-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxaitk_saliency = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxgrammar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxinference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxtts-api-server = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolo-poser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolov5 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolov7-package = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyta-general-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzensvi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzetascale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzuko = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n","size_bytes":90754},"replit.md":{"content":"# ExoDetect: Exoplanet Classification System\n\n## Overview\n\nExoDetect is a machine learning application for classifying exoplanets from NASA's Kepler mission data. The system uses ensemble methods (XGBoost, LightGBM, Random Forest) to predict object disposition into three categories: Confirmed, Candidate, or False Positive. Built with Streamlit for the web interface, the application provides data preprocessing, model training, hyperparameter optimization, model calibration, and explainability features through SHAP integration.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Frontend Architecture\n**Technology**: Streamlit web framework\n\n**Design Pattern**: Single-page application with cached resources\n\n**Rationale**: Streamlit provides rapid development for data science applications with built-in state management and component rendering. The `@st.cache_resource` decorator ensures model artifacts are loaded once and reused across sessions, improving performance.\n\n**Key Components**:\n- Interactive visualizations using Plotly and Matplotlib\n- Real-time model predictions and explanations\n- File upload capabilities for custom datasets\n- Multi-panel layout with sidebar navigation\n\n### Backend Architecture\n\n**Core Processing Modules**:\n\n1. **Data Preprocessing** (`utils/data_preprocessing.py`)\n   - **Purpose**: Transform raw NASA exoplanet data into ML-ready format\n   - **Approach**: Pipeline-based preprocessing with sklearn's StandardScaler and SimpleImputer\n   - **Key Decisions**: \n     - Median imputation for missing values (robust to outliers in astronomical data)\n     - Log transformation for highly skewed features (period, depth, insolation)\n     - Automatic label detection and standardization from multiple disposition formats\n   - **Rationale**: Astronomical data often has heavy-tailed distributions; log transforms normalize these for better model performance\n\n2. **Feature Engineering** (`utils/feature_engineering.py`)\n   - **Purpose**: Create domain-specific derived features from raw measurements\n   - **Approach**: Generate ratio and difference features between related astronomical properties\n   - **Examples**: Planet-to-star radius ratios, transit depth-to-duration ratios\n   - **Rationale**: Physical relationships between features (like radius ratios) carry more predictive power than raw measurements alone\n\n3. **Model Training** (`utils/model_training.py`)\n   - **Architecture**: Multi-model support with fallback mechanisms\n   - **Supported Models**: XGBoost (primary), LightGBM (alternative), Random Forest (fallback)\n   - **Design Pattern**: Factory pattern for model creation with dynamic availability checking\n   - **Rationale**: XGBoost/LightGBM excel at tabular classification but aren't always available in all environments; Random Forest provides a reliable fallback\n   - **Class Imbalance Handling**: Computed class weights to handle imbalanced datasets common in exoplanet detection\n\n4. **Ensemble Methods** (`utils/ensemble_models.py`)\n   - **Architecture**: Stacking classifier combining multiple base estimators\n   - **Approach**: Use XGBoost and Random Forest as base models with Logistic Regression meta-learner\n   - **Rationale**: Different models capture different patterns; stacking combines their strengths while the meta-learner learns optimal weighting\n\n5. **Hyperparameter Optimization** (`utils/hyperparameter_tuning.py`)\n   - **Method**: Randomized search with stratified k-fold cross-validation\n   - **Rationale**: Randomized search provides good results faster than grid search while maintaining exploration of parameter space\n   - **Cross-validation**: Stratified folds preserve class distribution across imbalanced classes\n\n6. **Model Calibration** (`utils/calibration_utils.py`)\n   - **Purpose**: Ensure predicted probabilities reflect true likelihood\n   - **Metrics**: Calibration curves and Brier scores for each class\n   - **Rationale**: Well-calibrated probabilities are crucial for decision-making in astronomical classification where false positives have real observational costs\n\n7. **Model Explainability** (`utils/shap_utils.py`)\n   - **Technology**: SHAP (SHapley Additive exPlanations)\n   - **Approach**: TreeExplainer for tree-based models with KernelExplainer fallback\n   - **Rationale**: SHAP provides theoretically-grounded feature importance with both global and local explanations, essential for scientific validation\n\n### Data Flow\n\n1. **Input**: CSV file from NASA Kepler mission (cumulative dataset)\n2. **Preprocessing**: Label detection ‚Üí standardization ‚Üí feature selection ‚Üí imputation ‚Üí scaling ‚Üí log transforms\n3. **Feature Engineering**: Generate ratio and difference features\n4. **Model Training**: Train with class weights ‚Üí cross-validation ‚Üí hyperparameter tuning\n5. **Ensemble**: Combine multiple models via stacking\n6. **Calibration**: Adjust probabilities for reliability\n7. **Prediction**: Generate classifications with confidence scores and SHAP explanations\n8. **Persistence**: Save model artifacts (joblib) and feature metadata (JSON)\n\n### Model Persistence\n\n**Format**: Joblib for serialized Python objects (models, preprocessors)\n\n**Artifacts Saved**:\n- Trained model (`model.joblib`)\n- Preprocessing pipeline (`preprocessor.joblib`)\n- Feature names list (`feature_list.json`)\n\n**Rationale**: Joblib provides efficient serialization for scikit-learn compatible objects with compression support\n\n### Error Handling Strategy\n\n**Graceful Degradation**: Optional dependencies (XGBoost, LightGBM, SHAP) have try-except imports with fallback logic\n\n**Rationale**: Ensures application runs in constrained environments while providing enhanced features when available\n\n### Performance Optimizations\n\n- Resource caching via Streamlit decorators\n- Lazy loading of heavy dependencies\n- Stratified sampling for SHAP explanations (limited to 100 samples for kernel explainer)\n- Parallel processing where supported (n_jobs=-1)\n\n## External Dependencies\n\n### Core ML Libraries\n- **scikit-learn**: Preprocessing pipelines, model evaluation, ensemble methods\n- **pandas**: Data manipulation and CSV handling\n- **numpy**: Numerical operations and array handling\n\n### Gradient Boosting Frameworks\n- **XGBoost** (optional): Primary classification model for tabular data\n- **LightGBM** (optional): Alternative gradient boosting implementation\n\n### Explainability\n- **SHAP** (optional): Model interpretability and feature importance\n\n### Visualization\n- **Plotly**: Interactive charts and graphs for web interface\n- **Matplotlib**: Static plots for calibration curves\n- **Seaborn**: Enhanced statistical visualizations\n\n### Web Framework\n- **Streamlit**: Complete web application framework with built-in components\n\n### Model Persistence\n- **joblib**: Model serialization and deserialization\n\n### Data Source\n- **NASA Exoplanet Archive**: Cumulative Kepler Object of Interest (KOI) dataset\n  - Format: CSV with comment lines\n  - Target: `koi_disposition` or similar disposition column\n  - Features: Orbital parameters (period, duration), planetary properties (radius, depth), stellar properties (temperature, radius)\n\n### Configuration\n- No external configuration management system\n- Parameters hardcoded in module initialization\n- Random state set to 42 for reproducibility","size_bytes":7338},"utils/calibration_utils.py":{"content":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.calibration import calibration_curve\nfrom sklearn.metrics import brier_score_loss, precision_recall_curve, f1_score, precision_score, recall_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass ModelCalibration:\n    def __init__(self, model, X_test, y_test, class_names):\n        self.model = model\n        self.X_test = X_test\n        self.y_test = y_test\n        self.class_names = class_names\n        self.y_proba = model.predict_proba(X_test)\n        \n    def plot_calibration_curve(self, class_idx=0, n_bins=10):\n        \"\"\"Plot calibration curve for a specific class\"\"\"\n        # Get probabilities for the target class\n        y_prob = self.y_proba[:, class_idx]\n        \n        # Binarize the labels for this class\n        y_binary = (self.y_test == class_idx).astype(int)\n        \n        # Calculate calibration curve\n        fraction_of_positives, mean_predicted_value = calibration_curve(\n            y_binary, y_prob, n_bins=n_bins, strategy='uniform'\n        )\n        \n        # Calculate Brier score\n        brier_score = brier_score_loss(y_binary, y_prob)\n        \n        # Create plot\n        fig, ax = plt.subplots(figsize=(8, 6))\n        \n        # Plot calibration curve\n        ax.plot(mean_predicted_value, fraction_of_positives, 's-', \n               label=f'{self.class_names[class_idx]} (Brier: {brier_score:.3f})')\n        \n        # Plot perfectly calibrated line\n        ax.plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n        \n        ax.set_xlabel('Mean Predicted Probability')\n        ax.set_ylabel('Fraction of Positives')\n        ax.set_title(f'Calibration Curve - {self.class_names[class_idx]}')\n        ax.legend()\n        ax.grid(True, alpha=0.3)\n        \n        return fig, brier_score\n    \n    def plot_all_calibration_curves(self, n_bins=10):\n        \"\"\"Plot calibration curves for all classes\"\"\"\n        n_classes = len(self.class_names)\n        fig, axes = plt.subplots(1, n_classes, figsize=(6*n_classes, 5))\n        \n        if n_classes == 1:\n            axes = [axes]\n        \n        brier_scores = {}\n        \n        for class_idx, ax in enumerate(axes):\n            y_prob = self.y_proba[:, class_idx]\n            y_binary = (self.y_test == class_idx).astype(int)\n            \n            fraction_of_positives, mean_predicted_value = calibration_curve(\n                y_binary, y_prob, n_bins=n_bins, strategy='uniform'\n            )\n            \n            brier_score = brier_score_loss(y_binary, y_prob)\n            brier_scores[self.class_names[class_idx]] = brier_score\n            \n            ax.plot(mean_predicted_value, fraction_of_positives, 's-', \n                   label=f'Brier: {brier_score:.3f}')\n            ax.plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n            \n            ax.set_xlabel('Mean Predicted Probability')\n            ax.set_ylabel('Fraction of Positives')\n            ax.set_title(f'{self.class_names[class_idx]}')\n            ax.legend()\n            ax.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        \n        return fig, brier_scores\n    \n    def find_optimal_threshold(self, class_idx=0, metric='f1'):\n        \"\"\"Find optimal probability threshold for a specific class\"\"\"\n        y_prob = self.y_proba[:, class_idx]\n        y_binary = (self.y_test == class_idx).astype(int)\n        \n        # Calculate precision-recall curve\n        precision, recall, thresholds = precision_recall_curve(y_binary, y_prob)\n        \n        # Calculate F1 score for each threshold\n        f1_scores = []\n        for i in range(len(thresholds)):\n            y_pred_thresh = (y_prob >= thresholds[i]).astype(int)\n            if metric == 'f1':\n                score = f1_score(y_binary, y_pred_thresh, zero_division=0)\n            elif metric == 'precision':\n                score = precision_score(y_binary, y_pred_thresh, zero_division=0)\n            elif metric == 'recall':\n                score = recall_score(y_binary, y_pred_thresh, zero_division=0)\n            f1_scores.append(score)\n        \n        # Find optimal threshold\n        if len(f1_scores) > 0:\n            optimal_idx = np.argmax(f1_scores)\n            optimal_threshold = thresholds[optimal_idx]\n            optimal_score = f1_scores[optimal_idx]\n        else:\n            optimal_threshold = 0.5\n            optimal_score = 0.0\n        \n        return {\n            'threshold': optimal_threshold,\n            'score': optimal_score,\n            'precision': precision,\n            'recall': recall,\n            'thresholds': thresholds,\n            'scores': f1_scores\n        }\n    \n    def plot_threshold_analysis(self, class_idx=0):\n        \"\"\"Plot threshold analysis for precision, recall, and F1\"\"\"\n        y_prob = self.y_proba[:, class_idx]\n        y_binary = (self.y_test == class_idx).astype(int)\n        \n        # Calculate metrics for different thresholds\n        thresholds = np.linspace(0, 1, 100)\n        precisions = []\n        recalls = []\n        f1_scores_list = []\n        \n        for thresh in thresholds:\n            y_pred = (y_prob >= thresh).astype(int)\n            \n            prec = precision_score(y_binary, y_pred, zero_division=0)\n            rec = recall_score(y_binary, y_pred, zero_division=0)\n            f1 = f1_score(y_binary, y_pred, zero_division=0)\n            \n            precisions.append(prec)\n            recalls.append(rec)\n            f1_scores_list.append(f1)\n        \n        # Find optimal F1 threshold\n        optimal_idx = np.argmax(f1_scores_list)\n        optimal_threshold = thresholds[optimal_idx]\n        \n        # Create plot\n        fig, ax = plt.subplots(figsize=(10, 6))\n        \n        ax.plot(thresholds, precisions, label='Precision', linewidth=2)\n        ax.plot(thresholds, recalls, label='Recall', linewidth=2)\n        ax.plot(thresholds, f1_scores_list, label='F1-Score', linewidth=2)\n        ax.axvline(optimal_threshold, color='red', linestyle='--', \n                  label=f'Optimal threshold: {optimal_threshold:.3f}', linewidth=2)\n        ax.axvline(0.5, color='gray', linestyle=':', \n                  label='Default threshold: 0.5', linewidth=1)\n        \n        ax.set_xlabel('Probability Threshold')\n        ax.set_ylabel('Score')\n        ax.set_title(f'Threshold Analysis - {self.class_names[class_idx]}')\n        ax.legend()\n        ax.grid(True, alpha=0.3)\n        ax.set_xlim([0, 1])\n        ax.set_ylim([0, 1.05])\n        \n        return fig, optimal_threshold\n    \n    def get_threshold_recommendations(self):\n        \"\"\"Get threshold recommendations for all classes\"\"\"\n        recommendations = {}\n        \n        for class_idx in range(len(self.class_names)):\n            class_name = self.class_names[class_idx]\n            \n            # Find optimal thresholds for different metrics\n            f1_result = self.find_optimal_threshold(class_idx, metric='f1')\n            prec_result = self.find_optimal_threshold(class_idx, metric='precision')\n            rec_result = self.find_optimal_threshold(class_idx, metric='recall')\n            \n            recommendations[class_name] = {\n                'f1_threshold': f1_result['threshold'],\n                'f1_score': f1_result['score'],\n                'precision_threshold': prec_result['threshold'],\n                'recall_threshold': rec_result['threshold']\n            }\n        \n        return recommendations\n","size_bytes":7447},"utils/data_preprocessing.py":{"content":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass ExoplanetPreprocessor:\n    def __init__(self):\n        self.scaler = StandardScaler()\n        self.imputer = SimpleImputer(strategy='median')\n        self.feature_names = None\n        self.log_transform_features = []\n        \n    def detect_label_column(self, df):\n        \"\"\"Detect the disposition/label column in the dataset\"\"\"\n        label_keywords = ['dispos', 'disp', 'status', 'koi_disposition', 'tfopwg_disp']\n        \n        for col in df.columns:\n            col_lower = col.lower()\n            if any(keyword in col_lower for keyword in label_keywords):\n                return col\n        \n        return None\n    \n    def standardize_labels(self, labels):\n        \"\"\"Convert various disposition labels to standard format\"\"\"\n        standardized = []\n        \n        for label in labels:\n            if pd.isna(label):\n                standardized.append(np.nan)\n                continue\n                \n            label_str = str(label).upper()\n            \n            if any(keyword in label_str for keyword in ['CONFIRMED', 'CP', 'KP']):\n                standardized.append('Confirmed')\n            elif any(keyword in label_str for keyword in ['CANDIDATE', 'PC', 'PC?', 'PC+']):\n                standardized.append('Candidate')  \n            elif any(keyword in label_str for keyword in ['FALSE', 'FP', 'REFUTED']):\n                standardized.append('False Positive')\n            else:\n                standardized.append(np.nan)\n                \n        return standardized\n    \n    def select_features(self, df):\n        \"\"\"Select relevant numerical features for classification\"\"\"\n        # Priority keywords for feature selection\n        priority_keywords = [\n            'period', 'duration', 'prad', 'depth', 'snr', 'mes', \n            'teff', 'insol', 'mag', 'flux', 'impact', 'rad', 'teq'\n        ]\n        \n        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n        \n        # First, find features matching priority keywords\n        selected_features = []\n        for col in numeric_cols:\n            col_lower = col.lower()\n            if any(keyword in col_lower for keyword in priority_keywords):\n                selected_features.append(col)\n        \n        # If we have fewer than 6 features, add more numeric columns\n        if len(selected_features) < 6:\n            remaining_numeric = [col for col in numeric_cols if col not in selected_features]\n            needed = min(30 - len(selected_features), len(remaining_numeric))\n            selected_features.extend(remaining_numeric[:needed])\n        \n        # Limit to 30 features maximum\n        selected_features = selected_features[:30]\n        \n        return selected_features\n    \n    def identify_log_transform_features(self, df, features):\n        \"\"\"Identify features that should be log-transformed due to high skewness\"\"\"\n        log_features = []\n        \n        for feature in features:\n            if feature in df.columns:\n                # Check if feature is positive and highly skewed\n                values = df[feature].dropna()\n                if len(values) > 0 and (values > 0).all():\n                    skewness = values.skew()\n                    if skewness > 2:  # Highly right-skewed\n                        # Common features that benefit from log transform\n                        if any(keyword in feature.lower() for keyword in \n                               ['period', 'depth', 'insol', 'flux', 'duration']):\n                            log_features.append(feature)\n        \n        return log_features\n    \n    def preprocess_data(self, df):\n        \"\"\"Complete preprocessing pipeline\"\"\"\n        try:\n            # Detect label column\n            label_column = self.detect_label_column(df)\n            if not label_column:\n                raise ValueError(\"Could not find disposition/label column\")\n            \n            print(f\"Found label column: {label_column}\")\n            \n            # Standardize labels\n            y = self.standardize_labels(df[label_column])\n            y = pd.Series(y)\n            \n            # Remove rows with missing labels\n            valid_labels = ~y.isna()\n            y = y[valid_labels]\n            df_filtered = df[valid_labels].copy()\n            \n            print(f\"Label distribution after filtering: {y.value_counts()}\")\n            \n            # Select features\n            selected_features = self.select_features(df_filtered)\n            if len(selected_features) < 3:\n                raise ValueError(\"Insufficient features found\")\n            \n            print(f\"Selected {len(selected_features)} features: {selected_features}\")\n            \n            # Filter features and remove rows with too many missing values\n            X = df_filtered[selected_features].copy()\n            \n            # Require at least 3 non-null features per row\n            min_features = min(3, len(selected_features))\n            valid_rows = X.count(axis=1) >= min_features\n            X = X[valid_rows]\n            y = y[valid_rows]\n            \n            print(f\"After filtering: {len(X)} rows, {len(X.columns)} features\")\n            \n            if len(X) < 10:\n                raise ValueError(\"Insufficient data after preprocessing\")\n            \n            # Identify log transform features\n            self.log_transform_features = self.identify_log_transform_features(X, selected_features)\n            print(f\"Log transform features: {self.log_transform_features}\")\n            \n            # Apply log transform\n            for feature in self.log_transform_features:\n                if feature in X.columns:\n                    # Add small constant to avoid log(0)\n                    X[feature] = np.log1p(X[feature].clip(lower=0))\n            \n            # Impute missing values\n            X_imputed = self.imputer.fit_transform(X)\n            \n            # Scale features\n            X_scaled = self.scaler.fit_transform(X_imputed)\n            \n            # Store feature names\n            self.feature_names = selected_features\n            \n            return X_scaled, y.values, selected_features\n            \n        except Exception as e:\n            print(f\"Preprocessing error: {str(e)}\")\n            return None, None, None\n    \n    def transform_new_data(self, df, feature_names=None):\n        \"\"\"Transform new data using fitted preprocessor\"\"\"\n        try:\n            if feature_names is None:\n                feature_names = self.feature_names\n            \n            if feature_names is None:\n                raise ValueError(\"No feature names available. Please fit the preprocessor first.\")\n            \n            # Check if required features exist\n            missing_features = [f for f in feature_names if f not in df.columns]\n            if missing_features:\n                print(f\"Warning: Missing features {missing_features}\")\n                # Create missing columns with NaN\n                for feature in missing_features:\n                    df[feature] = np.nan\n            \n            # Select and order features\n            X = df[feature_names].copy()\n            \n            # Apply same log transforms\n            for feature in self.log_transform_features:\n                if feature in X.columns:\n                    X[feature] = np.log1p(X[feature].clip(lower=0))\n            \n            # Apply imputation and scaling\n            X_imputed = self.imputer.transform(X)\n            X_scaled = self.scaler.transform(X_imputed)\n            \n            return X_scaled\n            \n        except Exception as e:\n            print(f\"Transform error: {str(e)}\")\n            return None\n","size_bytes":7868},"utils/ensemble_models.py":{"content":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntry:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    XGBOOST_AVAILABLE = False\n\nclass EnsembleClassifier:\n    def __init__(self, random_state=42):\n        self.random_state = random_state\n        self.stacking_model = None\n        self.label_encoder = None\n        \n    def create_base_estimators(self, class_weights_dict):\n        \"\"\"Create base estimators for the ensemble\"\"\"\n        estimators = []\n        \n        # XGBoost estimator (if available)\n        if XGBOOST_AVAILABLE:\n            xgb_model = xgb.XGBClassifier(\n                objective='multi:softprob',\n                n_estimators=200,\n                max_depth=6,\n                learning_rate=0.05,\n                subsample=0.8,\n                colsample_bytree=0.8,\n                random_state=self.random_state,\n                eval_metric='mlogloss',\n                n_jobs=-1\n            )\n            estimators.append(('xgboost', xgb_model))\n        \n        # RandomForest estimator\n        rf_model = RandomForestClassifier(\n            n_estimators=200,\n            max_depth=10,\n            class_weight='balanced',\n            random_state=self.random_state,\n            n_jobs=-1\n        )\n        estimators.append(('random_forest', rf_model))\n        \n        # Add a second RandomForest with different parameters for diversity\n        rf_model2 = RandomForestClassifier(\n            n_estimators=300,\n            max_depth=15,\n            min_samples_split=10,\n            class_weight='balanced',\n            random_state=self.random_state + 1,\n            n_jobs=-1\n        )\n        estimators.append(('random_forest_2', rf_model2))\n        \n        return estimators\n    \n    def create_stacking_classifier(self, estimators):\n        \"\"\"Create stacking classifier with meta-learner\"\"\"\n        # Use Logistic Regression as the meta-learner\n        meta_learner = LogisticRegression(\n            multi_class='multinomial',\n            solver='lbfgs',\n            max_iter=1000,\n            random_state=self.random_state,\n            class_weight='balanced'\n        )\n        \n        # Create stacking classifier\n        stacking_clf = StackingClassifier(\n            estimators=estimators,\n            final_estimator=meta_learner,\n            cv=5,  # Use 5-fold cross-validation for meta-features\n            stack_method='predict_proba',  # Use probabilities as meta-features\n            n_jobs=-1,\n            verbose=0\n        )\n        \n        return stacking_clf\n    \n    def train(self, X, y, label_encoder):\n        \"\"\"Train the stacking ensemble\"\"\"\n        self.label_encoder = label_encoder\n        \n        # Calculate class weights\n        classes = np.unique(y)\n        class_weights = compute_class_weight('balanced', classes=classes, y=y)\n        class_weights_dict = dict(zip(classes, class_weights))\n        \n        print(\"Creating ensemble with base estimators...\")\n        # Create base estimators\n        estimators = self.create_base_estimators(class_weights_dict)\n        \n        print(f\"Base estimators: {[name for name, _ in estimators]}\")\n        \n        # Create stacking classifier\n        print(\"Creating stacking classifier...\")\n        self.stacking_model = self.create_stacking_classifier(estimators)\n        \n        # For XGBoost in ensemble, we need sample weights\n        if XGBOOST_AVAILABLE:\n            sample_weights = np.array([class_weights_dict[label] for label in y])\n            print(\"Training ensemble with sample weights...\")\n            self.stacking_model.fit(X, y, sample_weight=sample_weights)\n        else:\n            print(\"Training ensemble...\")\n            self.stacking_model.fit(X, y)\n        \n        print(\"Ensemble training completed!\")\n        \n        return self.stacking_model\n    \n    def evaluate_base_models(self, X, y, cv=5):\n        \"\"\"Evaluate individual base models using cross-validation\"\"\"\n        results = {}\n        \n        # Calculate class weights\n        classes = np.unique(y)\n        class_weights = compute_class_weight('balanced', classes=classes, y=y)\n        class_weights_dict = dict(zip(classes, class_weights))\n        \n        estimators = self.create_base_estimators(class_weights_dict)\n        cv_splitter = StratifiedKFold(n_splits=cv, shuffle=True, random_state=self.random_state)\n        \n        for name, estimator in estimators:\n            print(f\"Evaluating {name}...\")\n            if name == 'xgboost' and XGBOOST_AVAILABLE:\n                # For XGBoost, we need to handle sample weights in CV\n                sample_weights = np.array([class_weights_dict[label] for label in y])\n                scores = cross_val_score(estimator, X, y, cv=cv_splitter, scoring='f1_macro', n_jobs=-1)\n            else:\n                scores = cross_val_score(estimator, X, y, cv=cv_splitter, scoring='f1_macro', n_jobs=-1)\n            \n            results[name] = {\n                'cv_scores': scores,\n                'mean_score': scores.mean(),\n                'std_score': scores.std()\n            }\n            print(f\"{name}: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n        \n        return results\n    \n    def predict(self, X):\n        \"\"\"Make predictions\"\"\"\n        if self.stacking_model is None:\n            raise ValueError(\"Model not trained yet\")\n        return self.stacking_model.predict(X)\n    \n    def predict_proba(self, X):\n        \"\"\"Get prediction probabilities\"\"\"\n        if self.stacking_model is None:\n            raise ValueError(\"Model not trained yet\")\n        return self.stacking_model.predict_proba(X)\n    \n    def get_feature_importance(self):\n        \"\"\"Get feature importance from base models (if available)\"\"\"\n        if self.stacking_model is None:\n            return None\n        \n        # Try to get feature importance from the first base estimator that supports it\n        for estimator in self.stacking_model.estimators_:\n            if hasattr(estimator, 'feature_importances_'):\n                return estimator.feature_importances_\n        \n        return None\n","size_bytes":6454},"utils/feature_engineering.py":{"content":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom itertools import combinations\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass ExoplanetFeatureEngineer:\n    def __init__(self):\n        self.poly_features = None\n        self.derived_feature_names = []\n        self.original_feature_names = []\n        \n    def create_ratio_features(self, df, feature_names):\n        \"\"\"Create ratio features from pairs of related features\"\"\"\n        ratio_features = pd.DataFrame(index=df.index)\n        ratio_names = []\n        \n        # Define feature pairs that make sense for ratios\n        ratio_pairs = [\n            ('prad', 'srad'),  # Planet radius to star radius\n            ('depth', 'duration'),  # Transit depth to duration\n            ('period', 'duration'),  # Orbital period to transit duration\n            ('insol', 'teq'),  # Insolation to equilibrium temperature\n        ]\n        \n        for feat1_key, feat2_key in ratio_pairs:\n            # Find matching features\n            feat1_cols = [f for f in feature_names if feat1_key in f.lower()]\n            feat2_cols = [f for f in feature_names if feat2_key in f.lower()]\n            \n            for f1 in feat1_cols:\n                for f2 in feat2_cols:\n                    if f1 in df.columns and f2 in df.columns:\n                        # Avoid division by zero\n                        denominator = df[f2].replace(0, np.nan)\n                        ratio = df[f1] / denominator\n                        \n                        if not ratio.isna().all():  # Only add if not all NaN\n                            ratio_name = f\"{f1}_to_{f2}_ratio\"\n                            ratio_features[ratio_name] = ratio\n                            ratio_names.append(ratio_name)\n        \n        return ratio_features, ratio_names\n    \n    def create_difference_features(self, df, feature_names):\n        \"\"\"Create difference features from related features\"\"\"\n        diff_features = pd.DataFrame(index=df.index)\n        diff_names = []\n        \n        # Features that make sense to subtract\n        diff_keywords = ['err1', 'err2', 'upper', 'lower']\n        \n        # Group features by base name\n        base_features = {}\n        for feat in feature_names:\n            base = feat.split('_err')[0].split('_upper')[0].split('_lower')[0]\n            if base not in base_features:\n                base_features[base] = []\n            base_features[base].append(feat)\n        \n        # Create differences for error bounds\n        for base, feats in base_features.items():\n            err1_feat = [f for f in feats if 'err1' in f.lower()]\n            err2_feat = [f for f in feats if 'err2' in f.lower()]\n            \n            if len(err1_feat) == 1 and len(err2_feat) == 1:\n                if err1_feat[0] in df.columns and err2_feat[0] in df.columns:\n                    diff_name = f\"{base}_error_range\"\n                    diff_features[diff_name] = df[err1_feat[0]] - df[err2_feat[0]]\n                    diff_names.append(diff_name)\n        \n        return diff_features, diff_names\n    \n    def create_interaction_features(self, df, feature_names, max_interactions=10):\n        \"\"\"Create multiplicative interaction features\"\"\"\n        interaction_features = pd.DataFrame(index=df.index)\n        interaction_names = []\n        \n        # Select important feature types for interactions\n        important_keywords = ['period', 'depth', 'prad', 'duration', 'snr', 'teq']\n        important_features = []\n        \n        for keyword in important_keywords:\n            matching = [f for f in feature_names if keyword in f.lower() and f in df.columns]\n            if matching:\n                important_features.append(matching[0])  # Take first match\n        \n        # Limit to avoid explosion\n        important_features = important_features[:5]\n        \n        # Create pairwise interactions\n        count = 0\n        for f1, f2 in combinations(important_features, 2):\n            if count >= max_interactions:\n                break\n                \n            if f1 in df.columns and f2 in df.columns:\n                interaction_name = f\"{f1}_x_{f2}\"\n                interaction_features[interaction_name] = df[f1] * df[f2]\n                interaction_names.append(interaction_name)\n                count += 1\n        \n        return interaction_features, interaction_names\n    \n    def create_polynomial_features(self, df, feature_names, degree=2, max_features=5):\n        \"\"\"Create polynomial features for top features\"\"\"\n        # Select top features based on variance\n        numeric_df = df[feature_names].select_dtypes(include=[np.number])\n        \n        # Calculate variance and select top features\n        variances = numeric_df.var()\n        top_features = variances.nlargest(min(max_features, len(variances))).index.tolist()\n        \n        if len(top_features) == 0:\n            return pd.DataFrame(index=df.index), []\n        \n        # Create polynomial features\n        poly = PolynomialFeatures(degree=degree, include_bias=False, interaction_only=False)\n        \n        poly_array = poly.fit_transform(df[top_features].fillna(0))\n        poly_feature_names = poly.get_feature_names_out(top_features)\n        \n        # Remove original features (they're already in the dataset)\n        new_features_idx = [i for i, name in enumerate(poly_feature_names) \n                          if name not in top_features]\n        \n        poly_df = pd.DataFrame(\n            poly_array[:, new_features_idx],\n            columns=[poly_feature_names[i] for i in new_features_idx],\n            index=df.index\n        )\n        \n        self.poly_features = poly\n        \n        return poly_df, poly_df.columns.tolist()\n    \n    def engineer_features(self, df, feature_names, include_ratios=True, include_differences=True, \n                         include_interactions=True, include_polynomial=False):\n        \"\"\"Apply all feature engineering techniques\"\"\"\n        engineered_df = df[feature_names].copy()\n        new_feature_names = feature_names.copy()\n        self.original_feature_names = feature_names.copy()\n        \n        print(f\"Starting with {len(feature_names)} original features\")\n        \n        # Create ratio features\n        if include_ratios:\n            ratio_df, ratio_names = self.create_ratio_features(df, feature_names)\n            if len(ratio_names) > 0:\n                engineered_df = pd.concat([engineered_df, ratio_df], axis=1)\n                new_feature_names.extend(ratio_names)\n                print(f\"Added {len(ratio_names)} ratio features\")\n        \n        # Create difference features\n        if include_differences:\n            diff_df, diff_names = self.create_difference_features(df, feature_names)\n            if len(diff_names) > 0:\n                engineered_df = pd.concat([engineered_df, diff_df], axis=1)\n                new_feature_names.extend(diff_names)\n                print(f\"Added {len(diff_names)} difference features\")\n        \n        # Create interaction features\n        if include_interactions:\n            interaction_df, interaction_names = self.create_interaction_features(df, feature_names)\n            if len(interaction_names) > 0:\n                engineered_df = pd.concat([engineered_df, interaction_df], axis=1)\n                new_feature_names.extend(interaction_names)\n                print(f\"Added {len(interaction_names)} interaction features\")\n        \n        # Create polynomial features\n        if include_polynomial:\n            poly_df, poly_names = self.create_polynomial_features(df, feature_names, degree=2)\n            if len(poly_names) > 0:\n                engineered_df = pd.concat([engineered_df, poly_df], axis=1)\n                new_feature_names.extend(poly_names)\n                print(f\"Added {len(poly_names)} polynomial features\")\n        \n        self.derived_feature_names = [f for f in new_feature_names if f not in feature_names]\n        \n        print(f\"Total features after engineering: {len(new_feature_names)}\")\n        print(f\"New derived features: {len(self.derived_feature_names)}\")\n        \n        return engineered_df, new_feature_names\n    \n    def transform_new_data(self, df, original_feature_names):\n        \"\"\"Transform new data using the same feature engineering\"\"\"\n        # Apply the same transformations\n        return self.engineer_features(\n            df, \n            original_feature_names,\n            include_ratios=True,\n            include_differences=True,\n            include_interactions=True,\n            include_polynomial=False\n        )\n","size_bytes":8591},"utils/hyperparameter_tuning.py":{"content":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.class_weight import compute_class_weight\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntry:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    XGBOOST_AVAILABLE = False\n\nclass HyperparameterOptimizer:\n    def __init__(self, model_type='xgboost', n_iter=20, cv=5, random_state=42):\n        self.model_type = model_type.lower()\n        self.n_iter = n_iter\n        self.cv = cv\n        self.random_state = random_state\n        self.best_model = None\n        self.best_params = None\n        self.cv_results = None\n        \n    def get_param_distributions(self):\n        \"\"\"Get parameter distributions for hyperparameter search\"\"\"\n        if self.model_type == 'xgboost' and XGBOOST_AVAILABLE:\n            return {\n                'n_estimators': [100, 200, 300, 500],\n                'max_depth': [3, 4, 5, 6, 8, 10],\n                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n                'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n                'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n                'gamma': [0, 0.1, 0.5, 1],\n                'reg_lambda': [1, 5, 10, 20],\n                'min_child_weight': [1, 3, 5, 7]\n            }\n        else:  # RandomForest\n            return {\n                'n_estimators': [100, 200, 300, 500],\n                'max_depth': [5, 10, 15, 20, None],\n                'min_samples_split': [2, 5, 10, 20],\n                'min_samples_leaf': [1, 2, 4, 8],\n                'max_features': ['sqrt', 'log2', None],\n                'bootstrap': [True, False],\n                'criterion': ['gini', 'entropy']\n            }\n    \n    def create_base_model(self, class_weights_dict):\n        \"\"\"Create base model for hyperparameter search\"\"\"\n        if self.model_type == 'xgboost' and XGBOOST_AVAILABLE:\n            # XGBoost doesn't use class_weight directly, we'll use sample_weight during fit\n            return xgb.XGBClassifier(\n                objective='multi:softprob',\n                eval_metric='mlogloss',\n                random_state=self.random_state,\n                n_jobs=-1\n            )\n        else:\n            return RandomForestClassifier(\n                class_weight='balanced',\n                random_state=self.random_state,\n                n_jobs=-1\n            )\n    \n    def optimize(self, X, y, scoring='f1_macro'):\n        \"\"\"Perform hyperparameter optimization using RandomizedSearchCV\"\"\"\n        print(f\"Starting hyperparameter optimization for {self.model_type}\")\n        print(f\"Number of iterations: {self.n_iter}, CV folds: {self.cv}\")\n        \n        # Calculate class weights\n        classes = np.unique(y)\n        class_weights = compute_class_weight('balanced', classes=classes, y=y)\n        class_weights_dict = dict(zip(classes, class_weights))\n        \n        # Create base model\n        base_model = self.create_base_model(class_weights_dict)\n        \n        # Get parameter distributions\n        param_distributions = self.get_param_distributions()\n        \n        # Create stratified k-fold\n        cv_splitter = StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=self.random_state)\n        \n        # Perform randomized search\n        random_search = RandomizedSearchCV(\n            estimator=base_model,\n            param_distributions=param_distributions,\n            n_iter=self.n_iter,\n            scoring=scoring,\n            cv=cv_splitter,\n            verbose=1,\n            random_state=self.random_state,\n            n_jobs=-1,\n            return_train_score=True\n        )\n        \n        # For XGBoost, we need to pass sample_weight\n        if self.model_type == 'xgboost' and XGBOOST_AVAILABLE:\n            sample_weights = np.array([class_weights_dict[label] for label in y])\n            random_search.fit(X, y, sample_weight=sample_weights)\n        else:\n            random_search.fit(X, y)\n        \n        # Store results\n        self.best_model = random_search.best_estimator_\n        self.best_params = random_search.best_params_\n        self.cv_results = pd.DataFrame(random_search.cv_results_)\n        \n        print(f\"Best score: {random_search.best_score_:.4f}\")\n        print(f\"Best parameters: {self.best_params}\")\n        \n        return {\n            'best_model': self.best_model,\n            'best_params': self.best_params,\n            'best_score': random_search.best_score_,\n            'cv_results': self.cv_results\n        }\n    \n    def get_top_param_sets(self, n=5):\n        \"\"\"Get top N parameter sets from CV results\"\"\"\n        if self.cv_results is None:\n            return None\n        \n        # Sort by mean test score\n        sorted_results = self.cv_results.sort_values('mean_test_score', ascending=False)\n        \n        # Extract relevant columns\n        param_cols = [col for col in sorted_results.columns if col.startswith('param_')]\n        score_cols = ['mean_test_score', 'std_test_score', 'rank_test_score']\n        \n        top_results = sorted_results[param_cols + score_cols].head(n)\n        \n        return top_results\n","size_bytes":5195},"utils/model_training.py":{"content":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Try to import XGBoost and LightGBM\ntry:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    XGBOOST_AVAILABLE = False\n    print(\"XGBoost not available. Using RandomForest as fallback.\")\n\ntry:\n    import lightgbm as lgb\n    LIGHTGBM_AVAILABLE = True\nexcept (ImportError, OSError) as e:\n    LIGHTGBM_AVAILABLE = False\n    print(f\"LightGBM not available ({str(e)}). Using RandomForest as fallback.\")\n\nclass ExoplanetClassifier:\n    def __init__(self, model_type='xgboost'):\n        self.model_type = model_type.lower()\n        self.model = None\n        self.label_encoder = LabelEncoder()\n        \n    def create_model(self, n_classes, class_weights=None):\n        \"\"\"Create the specified model\"\"\"\n        if self.model_type == 'xgboost' and XGBOOST_AVAILABLE:\n            self.model = xgb.XGBClassifier(\n                objective='multi:softprob',\n                n_estimators=300,\n                max_depth=6,\n                learning_rate=0.05,\n                subsample=0.8,\n                colsample_bytree=0.8,\n                random_state=42,\n                eval_metric='mlogloss',\n                n_jobs=-1\n            )\n        elif self.model_type == 'lightgbm' and LIGHTGBM_AVAILABLE:\n            self.model = lgb.LGBMClassifier(\n                objective='multiclass',\n                n_estimators=300,\n                max_depth=6,\n                learning_rate=0.05,\n                subsample=0.8,\n                colsample_bytree=0.8,\n                random_state=42,\n                n_jobs=-1,\n                verbose=-1\n            )\n        else:\n            # Fallback to RandomForest\n            self.model = RandomForestClassifier(\n                n_estimators=300,\n                max_depth=10,\n                random_state=42,\n                class_weight='balanced',\n                n_jobs=-1\n            )\n            self.model_type = 'randomforest'\n    \n    def calculate_class_weights(self, y):\n        \"\"\"Calculate class weights for handling imbalanced data\"\"\"\n        classes = np.unique(y)\n        class_weights = compute_class_weight('balanced', classes=classes, y=y)\n        return dict(zip(classes, class_weights))\n    \n    def calculate_sample_weights(self, y_encoded, class_weights_dict):\n        \"\"\"Calculate sample weights from class weights\"\"\"\n        sample_weights = np.array([class_weights_dict[label] for label in y_encoded])\n        return sample_weights\n    \n    def train_and_evaluate(self, X, y, test_size=0.25, random_state=42):\n        \"\"\"Train and evaluate the model\"\"\"\n        try:\n            # Encode labels\n            y_encoded = self.label_encoder.fit_transform(y)\n            n_classes = len(self.label_encoder.classes_)\n            \n            print(f\"Training {self.model_type} model with {n_classes} classes\")\n            print(f\"Classes: {list(self.label_encoder.classes_)}\")\n            \n            # Split data\n            X_train, X_test, y_train, y_test = train_test_split(\n                X, y_encoded, test_size=test_size, random_state=random_state, stratify=y_encoded\n            )\n            \n            # Calculate class weights\n            class_weights_dict = self.calculate_class_weights(y_train)\n            print(f\"Class weights: {class_weights_dict}\")\n            \n            # Create model\n            self.create_model(n_classes, class_weights_dict)\n            \n            # Train model with appropriate weighting\n            if self.model_type in ['xgboost', 'lightgbm']:\n                # Use sample weights for gradient boosting models\n                sample_weights = self.calculate_sample_weights(y_train, class_weights_dict)\n                self.model.fit(X_train, y_train, sample_weight=sample_weights)\n            else:\n                # RandomForest uses class_weight parameter\n                self.model.fit(X_train, y_train)\n            \n            # Make predictions\n            y_pred = self.model.predict(X_test)\n            \n            # Calculate metrics\n            accuracy = accuracy_score(y_test, y_pred)\n            \n            # Classification report with original class names\n            target_names = list(self.label_encoder.classes_)\n            class_report = classification_report(\n                y_test, y_pred, \n                target_names=target_names,\n                output_dict=True,\n                zero_division=0\n            )\n            \n            conf_matrix = confusion_matrix(y_test, y_pred)\n            \n            # Feature importance\n            feature_importance = None\n            if hasattr(self.model, 'feature_importances_'):\n                feature_importance = self.model.feature_importances_\n            \n            results = {\n                'model': self.model,\n                'label_encoder': self.label_encoder,\n                'accuracy': accuracy,\n                'classification_report': class_report,\n                'confusion_matrix': conf_matrix,\n                'feature_importance': feature_importance,\n                'X_test': X_test,\n                'y_test': y_test,\n                'y_pred': y_pred\n            }\n            \n            return results\n            \n        except Exception as e:\n            print(f\"Training error: {str(e)}\")\n            raise e\n    \n    def predict(self, X):\n        \"\"\"Make predictions on new data\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not trained yet\")\n        \n        predictions_encoded = self.model.predict(X)\n        predictions = self.label_encoder.inverse_transform(predictions_encoded)\n        return predictions\n    \n    def predict_proba(self, X):\n        \"\"\"Get prediction probabilities\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not trained yet\")\n        \n        return self.model.predict_proba(X)\n","size_bytes":6205},"utils/shap_utils.py":{"content":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntry:\n    import shap\n    SHAP_AVAILABLE = True\nexcept ImportError:\n    SHAP_AVAILABLE = False\n    print(\"SHAP not available. Feature explanations will be limited.\")\n\nclass SHAPExplainer:\n    def __init__(self, model, X_background=None):\n        self.model = model\n        self.explainer = None\n        \n        if SHAP_AVAILABLE and X_background is not None:\n            try:\n                # Try TreeExplainer for tree-based models\n                if hasattr(model, 'predict_proba') and hasattr(model, 'feature_importances_'):\n                    self.explainer = shap.TreeExplainer(model)\n                else:\n                    # Fallback to KernelExplainer with a small sample\n                    sample_size = min(100, len(X_background))\n                    background_sample = X_background[:sample_size]\n                    self.explainer = shap.KernelExplainer(model.predict_proba, background_sample)\n            except Exception as e:\n                print(f\"Could not initialize SHAP explainer: {e}\")\n                self.explainer = None\n    \n    def explain_prediction(self, X):\n        \"\"\"Generate SHAP values for predictions\"\"\"\n        if not SHAP_AVAILABLE or self.explainer is None:\n            return None\n        \n        try:\n            shap_values = self.explainer.shap_values(X)\n            return shap_values\n        except Exception as e:\n            print(f\"Error generating SHAP values: {e}\")\n            return None\n    \n    def create_summary_plot(self, shap_values, X, feature_names=None, max_display=20):\n        \"\"\"Create SHAP summary plot\"\"\"\n        if not SHAP_AVAILABLE or shap_values is None:\n            return None\n        \n        try:\n            plt.figure(figsize=(10, 6))\n            if isinstance(shap_values, list):  # Multi-class case\n                # Use the first class for summary\n                shap.summary_plot(shap_values[0], X, feature_names=feature_names, \n                                show=False, max_display=max_display)\n            else:\n                shap.summary_plot(shap_values, X, feature_names=feature_names, \n                                show=False, max_display=max_display)\n            \n            return plt.gcf()\n        except Exception as e:\n            print(f\"Error creating SHAP summary plot: {e}\")\n            return None\n    \n    def create_waterfall_plot(self, shap_values, feature_names, prediction_class):\n        \"\"\"Create SHAP waterfall plot for a single prediction\"\"\"\n        if not SHAP_AVAILABLE or shap_values is None:\n            return None\n        \n        try:\n            # For multi-class, we might need to handle differently\n            if isinstance(shap_values, np.ndarray) and len(shap_values.shape) > 1:\n                # Take the first class or the predicted class\n                shap_values = shap_values[0] if len(shap_values.shape) > 1 else shap_values\n            \n            # Create a simple bar plot since waterfall might not be available in all SHAP versions\n            plt.figure(figsize=(10, 6))\n            \n            if feature_names and len(feature_names) == len(shap_values):\n                # Create feature importance bar plot\n                importance_data = pd.DataFrame({\n                    'feature': feature_names,\n                    'importance': np.abs(shap_values)\n                }).sort_values('importance', ascending=True)\n                \n                colors = ['red' if x < 0 else 'blue' for x in shap_values]\n                plt.barh(range(len(importance_data)), importance_data['importance'], \n                        color=colors[:len(importance_data)])\n                plt.yticks(range(len(importance_data)), importance_data['feature'])\n                plt.xlabel('Feature Importance (|SHAP value|)')\n                plt.title(f'Feature Importance for Prediction: {prediction_class}')\n                plt.tight_layout()\n                \n                return plt.gcf()\n            else:\n                return None\n                \n        except Exception as e:\n            print(f\"Error creating SHAP waterfall plot: {e}\")\n            return None\n    \n    def get_top_features(self, shap_values, feature_names, top_k=10):\n        \"\"\"Get top contributing features\"\"\"\n        if shap_values is None or feature_names is None:\n            return None\n        \n        try:\n            # Handle multi-class case\n            if isinstance(shap_values, list):\n                shap_values = shap_values[0]  # Use first class\n            \n            if len(shap_values.shape) > 1:\n                shap_values = shap_values[0]  # Use first prediction\n            \n            # Get absolute importance\n            abs_importance = np.abs(shap_values)\n            \n            # Get top features\n            top_indices = np.argsort(abs_importance)[-top_k:][::-1]\n            \n            top_features = []\n            for idx in top_indices:\n                if idx < len(feature_names):\n                    top_features.append({\n                        'feature': feature_names[idx],\n                        'importance': abs_importance[idx],\n                        'shap_value': shap_values[idx]\n                    })\n            \n            return top_features\n            \n        except Exception as e:\n            print(f\"Error getting top features: {e}\")\n            return None\n","size_bytes":5456}},"version":1}